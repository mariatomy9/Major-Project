{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mariatomy9/Major-Project/blob/lena/Copy_of_Project_displaysystem.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9B5Zl1UOBMAJ"
      },
      "source": [
        "Importing the Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YOCpZ1Vm6cfW"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import svm\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "XNlmCEz0rSWP",
        "outputId": "473a1ef1-40ba-40bc-b675-775d134cc1be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\r0% [Working]\r            \rHit:1 http://archive.ubuntu.com/ubuntu focal InRelease\n",
            "\r0% [Waiting for headers] [Waiting for headers] [Connected to cloud.r-project.or\r                                                                               \rGet:2 http://archive.ubuntu.com/ubuntu focal-updates InRelease [114 kB]\n",
            "\r                                                                               \rGet:3 http://security.ubuntu.com/ubuntu focal-security InRelease [114 kB]\n",
            "\r0% [2 InRelease 15.6 kB/114 kB 14%] [3 InRelease 20.0 kB/114 kB 18%] [Waiting f\r                                                                               \rGet:4 https://cloud.r-project.org/bin/linux/ubuntu focal-cran40/ InRelease [3,622 B]\n",
            "\r0% [2 InRelease 21.4 kB/114 kB 19%] [3 InRelease 46.0 kB/114 kB 40%] [4 InRelea\r0% [2 InRelease 21.4 kB/114 kB 19%] [3 InRelease 46.0 kB/114 kB 40%] [Waiting f\r                                                                               \rHit:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  InRelease\n",
            "\r0% [2 InRelease 53.3 kB/114 kB 47%] [3 InRelease 92.4 kB/114 kB 81%] [Waiting f\r                                                                               \r0% [2 InRelease 73.6 kB/114 kB 65%] [Waiting for headers]\r                                                         \r0% [Waiting for headers] [Waiting for headers]\r                                              \rHit:6 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu focal InRelease\n",
            "Get:7 http://archive.ubuntu.com/ubuntu focal-backports InRelease [108 kB]\n",
            "Hit:8 http://ppa.launchpad.net/cran/libgit2/ubuntu focal InRelease\n",
            "Hit:9 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal InRelease\n",
            "Hit:10 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu focal InRelease\n",
            "Get:11 http://security.ubuntu.com/ubuntu focal-security/main amd64 Packages [2,699 kB]\n",
            "Hit:12 http://ppa.launchpad.net/ubuntugis/ppa/ubuntu focal InRelease\n",
            "Get:13 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 Packages [1,344 kB]\n",
            "Get:14 http://security.ubuntu.com/ubuntu focal-security/universe amd64 Packages [1,049 kB]\n",
            "Get:15 http://security.ubuntu.com/ubuntu focal-security/restricted amd64 Packages [2,240 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 Packages [3,175 kB]\n",
            "Fetched 10.8 MB in 2s (4,568 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libblkid-dev libcairo-script-interpreter2 libglib2.0-dev libglib2.0-dev-bin\n",
            "  liblzo2-2 libmount-dev libpixman-1-dev libselinux1-dev libsepol1-dev\n",
            "  libxcb-render0-dev libxcb-shm0-dev\n",
            "Suggested packages:\n",
            "  libcairo2-doc libgirepository1.0-dev libglib2.0-doc libgdk-pixbuf2.0-bin\n",
            "  | libgdk-pixbuf2.0-dev libxml2-utils\n",
            "The following NEW packages will be installed:\n",
            "  libblkid-dev libcairo-script-interpreter2 libcairo2-dev libffi-dev\n",
            "  libglib2.0-dev libglib2.0-dev-bin liblzo2-2 libmount-dev libpixman-1-dev\n",
            "  libselinux1-dev libsepol1-dev libxcb-render0-dev libxcb-shm0-dev\n",
            "0 upgraded, 13 newly installed, 0 to remove and 27 not upgraded.\n",
            "Need to get 3,492 kB of archives.\n",
            "After this operation, 20.0 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu focal/main amd64 liblzo2-2 amd64 2.10-2 [50.8 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu focal/main amd64 libcairo-script-interpreter2 amd64 1.16.0-4ubuntu1 [54.2 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libpixman-1-dev amd64 0.38.4-0ubuntu2.1 [243 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu focal/main amd64 libxcb-render0-dev amd64 1.14-2 [18.4 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu focal/main amd64 libxcb-shm0-dev amd64 1.14-2 [6,716 B]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu focal/main amd64 libffi-dev amd64 3.3-4 [57.0 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libglib2.0-dev-bin amd64 2.64.6-1~ubuntu20.04.4 [109 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libblkid-dev amd64 2.34-0.1ubuntu9.3 [167 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libmount-dev amd64 2.34-0.1ubuntu9.3 [176 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libsepol1-dev amd64 3.0-1ubuntu0.1 [325 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu focal/main amd64 libselinux1-dev amd64 3.0-1build2 [151 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libglib2.0-dev amd64 2.64.6-1~ubuntu20.04.4 [1,506 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu focal/main amd64 libcairo2-dev amd64 1.16.0-4ubuntu1 [627 kB]\n",
            "Fetched 3,492 kB in 1s (5,425 kB/s)\n",
            "Selecting previously unselected package liblzo2-2:amd64.\n",
            "(Reading database ... 122531 files and directories currently installed.)\n",
            "Preparing to unpack .../00-liblzo2-2_2.10-2_amd64.deb ...\n",
            "Unpacking liblzo2-2:amd64 (2.10-2) ...\n",
            "Selecting previously unselected package libcairo-script-interpreter2:amd64.\n",
            "Preparing to unpack .../01-libcairo-script-interpreter2_1.16.0-4ubuntu1_amd64.deb ...\n",
            "Unpacking libcairo-script-interpreter2:amd64 (1.16.0-4ubuntu1) ...\n",
            "Selecting previously unselected package libpixman-1-dev:amd64.\n",
            "Preparing to unpack .../02-libpixman-1-dev_0.38.4-0ubuntu2.1_amd64.deb ...\n",
            "Unpacking libpixman-1-dev:amd64 (0.38.4-0ubuntu2.1) ...\n",
            "Selecting previously unselected package libxcb-render0-dev:amd64.\n",
            "Preparing to unpack .../03-libxcb-render0-dev_1.14-2_amd64.deb ...\n",
            "Unpacking libxcb-render0-dev:amd64 (1.14-2) ...\n",
            "Selecting previously unselected package libxcb-shm0-dev:amd64.\n",
            "Preparing to unpack .../04-libxcb-shm0-dev_1.14-2_amd64.deb ...\n",
            "Unpacking libxcb-shm0-dev:amd64 (1.14-2) ...\n",
            "Selecting previously unselected package libffi-dev:amd64.\n",
            "Preparing to unpack .../05-libffi-dev_3.3-4_amd64.deb ...\n",
            "Unpacking libffi-dev:amd64 (3.3-4) ...\n",
            "Selecting previously unselected package libglib2.0-dev-bin.\n",
            "Preparing to unpack .../06-libglib2.0-dev-bin_2.64.6-1~ubuntu20.04.4_amd64.deb ...\n",
            "Unpacking libglib2.0-dev-bin (2.64.6-1~ubuntu20.04.4) ...\n",
            "Selecting previously unselected package libblkid-dev:amd64.\n",
            "Preparing to unpack .../07-libblkid-dev_2.34-0.1ubuntu9.3_amd64.deb ...\n",
            "Unpacking libblkid-dev:amd64 (2.34-0.1ubuntu9.3) ...\n",
            "Selecting previously unselected package libmount-dev:amd64.\n",
            "Preparing to unpack .../08-libmount-dev_2.34-0.1ubuntu9.3_amd64.deb ...\n",
            "Unpacking libmount-dev:amd64 (2.34-0.1ubuntu9.3) ...\n",
            "Selecting previously unselected package libsepol1-dev:amd64.\n",
            "Preparing to unpack .../09-libsepol1-dev_3.0-1ubuntu0.1_amd64.deb ...\n",
            "Unpacking libsepol1-dev:amd64 (3.0-1ubuntu0.1) ...\n",
            "Selecting previously unselected package libselinux1-dev:amd64.\n",
            "Preparing to unpack .../10-libselinux1-dev_3.0-1build2_amd64.deb ...\n",
            "Unpacking libselinux1-dev:amd64 (3.0-1build2) ...\n",
            "Selecting previously unselected package libglib2.0-dev:amd64.\n",
            "Preparing to unpack .../11-libglib2.0-dev_2.64.6-1~ubuntu20.04.4_amd64.deb ...\n",
            "Unpacking libglib2.0-dev:amd64 (2.64.6-1~ubuntu20.04.4) ...\n",
            "Selecting previously unselected package libcairo2-dev:amd64.\n",
            "Preparing to unpack .../12-libcairo2-dev_1.16.0-4ubuntu1_amd64.deb ...\n",
            "Unpacking libcairo2-dev:amd64 (1.16.0-4ubuntu1) ...\n",
            "Setting up libglib2.0-dev-bin (2.64.6-1~ubuntu20.04.4) ...\n",
            "Setting up libblkid-dev:amd64 (2.34-0.1ubuntu9.3) ...\n",
            "Setting up libpixman-1-dev:amd64 (0.38.4-0ubuntu2.1) ...\n",
            "Setting up libsepol1-dev:amd64 (3.0-1ubuntu0.1) ...\n",
            "Setting up liblzo2-2:amd64 (2.10-2) ...\n",
            "Setting up libffi-dev:amd64 (3.3-4) ...\n",
            "Setting up libxcb-shm0-dev:amd64 (1.14-2) ...\n",
            "Setting up libxcb-render0-dev:amd64 (1.14-2) ...\n",
            "Setting up libmount-dev:amd64 (2.34-0.1ubuntu9.3) ...\n",
            "Setting up libcairo-script-interpreter2:amd64 (1.16.0-4ubuntu1) ...\n",
            "Setting up libselinux1-dev:amd64 (3.0-1build2) ...\n",
            "Setting up libglib2.0-dev:amd64 (2.64.6-1~ubuntu20.04.4) ...\n",
            "Processing triggers for libglib2.0-0:amd64 (2.64.6-1~ubuntu20.04.4) ...\n",
            "Processing triggers for libc-bin (2.31-0ubuntu9.9) ...\n",
            "Processing triggers for man-db (2.9.1-1) ...\n",
            "Setting up libcairo2-dev:amd64 (1.16.0-4ubuntu1) ...\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting reportlab\n",
            "  Using cached reportlab-4.0.0-py3-none-any.whl (1.9 MB)\n",
            "Collecting pillow>=9.0.0 (from reportlab)\n",
            "  Using cached Pillow-9.5.0-cp310-cp310-manylinux_2_28_x86_64.whl (3.4 MB)\n",
            "Collecting rlPyCairo<1,>=0.2.0 (from reportlab)\n",
            "  Using cached rlPyCairo-0.2.0-py3-none-any.whl (10 kB)\n",
            "Collecting freetype-py<2.4,>=2.3.0 (from reportlab)\n",
            "  Using cached freetype_py-2.3.0-py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (978 kB)\n",
            "Collecting pycairo>=1.20.0 (from rlPyCairo<1,>=0.2.0->reportlab)\n",
            "  Using cached pycairo-1.23.0.tar.gz (344 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: pycairo\n",
            "  Building wheel for pycairo (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycairo: filename=pycairo-1.23.0-cp310-cp310-linux_x86_64.whl size=331616 sha256=9538ddf6afd36cd9ff7a8ba1f4a581049340edd98b3de4f70ebebd9b06dcb7ae\n",
            "  Stored in directory: /root/.cache/pip/wheels/6d/63/63/4341460df2dca6490f16a23996298f277a3441f0b08bebe69b\n",
            "Successfully built pycairo\n",
            "Installing collected packages: pycairo, pillow, freetype-py, rlPyCairo, reportlab\n",
            "  Attempting uninstall: pillow\n",
            "    Found existing installation: Pillow 8.4.0\n",
            "    Uninstalling Pillow-8.4.0:\n",
            "      Successfully uninstalled Pillow-8.4.0\n",
            "Successfully installed freetype-py-2.3.0 pillow-9.5.0 pycairo-1.23.0 reportlab-4.0.0 rlPyCairo-0.2.0\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!apt-get update && apt-get install -y libffi-dev libcairo2-dev\n",
        "!pip install reportlab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P0FOAxG2rEBF",
        "outputId": "dbdea2de-ebf3-45d7-9a4f-c76c94a1bfe2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting eeglib\n",
            "  Downloading eeglib-0.4.1-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from eeglib) (1.22.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from eeglib) (1.10.1)\n",
            "Collecting sklearn (from eeglib)\n",
            "  Downloading sklearn-0.0.post5.tar.gz (3.7 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from eeglib) (0.56.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from eeglib) (1.5.3)\n",
            "Collecting pyedflib (from eeglib)\n",
            "  Downloading pyEDFlib-0.1.32-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m31.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fastdtw (from eeglib)\n",
            "  Downloading fastdtw-0.3.4.tar.gz (133 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.4/133.4 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: progressbar2 in /usr/local/lib/python3.10/dist-packages (from eeglib) (4.2.0)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->eeglib) (0.39.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from numba->eeglib) (67.7.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->eeglib) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->eeglib) (2022.7.1)\n",
            "Requirement already satisfied: python-utils>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from progressbar2->eeglib) (3.5.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->eeglib) (1.16.0)\n",
            "Building wheels for collected packages: fastdtw, sklearn\n",
            "  Building wheel for fastdtw (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fastdtw: filename=fastdtw-0.3.4-cp310-cp310-linux_x86_64.whl size=517905 sha256=a63d01017d61fcd497c0681c861b50eaa61af1d22d07a7d75d6797367d9863da\n",
            "  Stored in directory: /root/.cache/pip/wheels/73/c8/f7/c25448dab74c3acf4848bc25d513c736bb93910277e1528ef4\n",
            "  Building wheel for sklearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sklearn: filename=sklearn-0.0.post5-py3-none-any.whl size=2950 sha256=52f4e0d9f7b56b5f11d10187c0faacbc5d748086a10eae00eff019e0f298e665\n",
            "  Stored in directory: /root/.cache/pip/wheels/38/1f/8d/4f812c590e074c1e928f5cec67bf5053b71f38e2648739403a\n",
            "Successfully built fastdtw sklearn\n",
            "Installing collected packages: sklearn, pyedflib, fastdtw, eeglib\n",
            "Successfully installed eeglib-0.4.1 fastdtw-0.3.4 pyedflib-0.1.32 sklearn-0.0.post5\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting reportlab\n",
            "  Downloading reportlab-4.0.0-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pillow>=9.0.0 (from reportlab)\n",
            "  Downloading Pillow-9.5.0-cp310-cp310-manylinux_2_28_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m31.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rlPyCairo<1,>=0.2.0 (from reportlab)\n",
            "  Downloading rlPyCairo-0.2.0-py3-none-any.whl (10 kB)\n",
            "Collecting freetype-py<2.4,>=2.3.0 (from reportlab)\n",
            "  Downloading freetype_py-2.3.0-py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (978 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m978.9/978.9 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pycairo>=1.20.0 (from rlPyCairo<1,>=0.2.0->reportlab)\n",
            "  Downloading pycairo-1.23.0.tar.gz (344 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m344.6/344.6 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: pycairo\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mBuilding wheel for pycairo \u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mpyproject.toml\u001b[0m\u001b[1;32m)\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Building wheel for pycairo (pyproject.toml) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[31m  ERROR: Failed building wheel for pycairo\u001b[0m\u001b[31m\n",
            "\u001b[0mFailed to build pycairo\n",
            "\u001b[31mERROR: Could not build wheels for pycairo, which is required to install pyproject.toml-based projects\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m681.2/681.2 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pyngrok (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m48.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m164.8/164.8 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m82.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.1/82.1 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for validators (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting fpdf\n",
            "  Downloading fpdf-1.7.2.tar.gz (39 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: fpdf\n",
            "  Building wheel for fpdf (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fpdf: filename=fpdf-1.7.2-py2.py3-none-any.whl size=40704 sha256=d83c49cd92e9bda9df3848eaf5a982aceb3beec93d680b4117103dd06a7b6d0c\n",
            "  Stored in directory: /root/.cache/pip/wheels/f9/95/ba/f418094659025eb9611f17cbcaf2334236bf39a0c3453ea455\n",
            "Successfully built fpdf\n",
            "Installing collected packages: fpdf\n",
            "Successfully installed fpdf-1.7.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting mne\n",
            "  Downloading mne-1.4.0-py3-none-any.whl (7.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m51.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.10/dist-packages (from mne) (1.22.4)\n",
            "Requirement already satisfied: scipy>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from mne) (1.10.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mne) (3.7.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from mne) (4.65.0)\n",
            "Requirement already satisfied: pooch>=1.5 in /usr/local/lib/python3.10/dist-packages (from mne) (1.6.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from mne) (4.4.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from mne) (23.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from mne) (3.1.2)\n",
            "Requirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.5->mne) (1.4.4)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.5->mne) (2.27.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->mne) (2.1.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mne) (1.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mne) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mne) (4.39.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mne) (1.4.4)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mne) (8.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mne) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mne) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->mne) (1.16.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.4)\n",
            "Installing collected packages: mne\n",
            "Successfully installed mne-1.4.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyEDFlib in /usr/local/lib/python3.10/dist-packages (0.1.32)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.10/dist-packages (from pyEDFlib) (1.22.4)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting EDFlib-Python\n",
            "  Downloading EDFlib_Python-1.0.6-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from EDFlib-Python) (1.22.4)\n",
            "Installing collected packages: EDFlib-Python\n",
            "Successfully installed EDFlib-Python-1.0.6\n"
          ]
        }
      ],
      "source": [
        "!pip install eeglib\n",
        "\n",
        "!pip install -q pyngrok\n",
        "!pip install -q streamlit\n",
        "!pip install -q streamlit_ace\n",
        "!pip install PyPDF2\n",
        "!pip install fpdf\n",
        "!pip install mne\n",
        "!pip install pyEDFlib\n",
        "!pip install EDFlib-Python\n",
        "# !pip install fpdf\n",
        "# !pip install reportlab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SVg-n6neLKqJ",
        "outputId": "ee1465a5-9019-4754-db15-fe2adb7dce98"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7rSjfzlh-_f"
      },
      "source": [
        "Epilepsy Classification\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E-WjSEh1l5T5"
      },
      "source": [
        "Implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qomeA6VMl63i"
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function\n",
        "import os\n",
        "import time\n",
        "import random\n",
        "import glob\n",
        "import librosa\n",
        "import numpy as np\n",
        "import librosa.display\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from numpy import loadtxt\n",
        "import seaborn as sn\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uu8A5chBl-9m"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from keras.utils import np_utils\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.callbacks import  ModelCheckpoint\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from keras.layers.core import Dense, Activation\n",
        "from keras.layers.core import Dropout\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.layers import Dropout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uKPcb4-Sl_FZ",
        "outputId": "aee8a3aa-af57-46ce-c3b4-8afba835ff3e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "           PFD0      PFD1      PFD2      PFD3      PFD4      PFD5      PFD6  \\\n",
            "0      1.026628  1.026628  1.026114  1.026886  1.026628  1.026628  1.025081   \n",
            "1      1.026628  1.026628  1.026628  1.026886  1.026628  1.026628  1.026628   \n",
            "2      1.026886  1.026628  1.026114  1.026886  1.026628  1.026114  1.026114   \n",
            "3      1.026886  1.026628  1.026114  1.026628  1.026628  1.025598  1.026114   \n",
            "4      1.026628  1.026628  1.026114  1.026628  1.026628  1.027399  1.026628   \n",
            "...         ...       ...       ...       ...       ...       ...       ...   \n",
            "28339  1.021963  1.025598  1.026628  1.016426  1.027142  1.024045  1.020391   \n",
            "28340  1.019075  1.024564  1.026628  1.020654  1.024305  1.026371  1.022485   \n",
            "28341  1.020654  1.025081  1.026628  1.017754  1.023266  1.021963  1.018547   \n",
            "28342  1.020391  1.024823  1.026628  1.015893  1.024305  1.025081  1.018812   \n",
            "28343  1.003083  1.005580  1.005304  1.005580  1.005304  1.004750  1.003918   \n",
            "\n",
            "           PFD7      PFD8      PFD9  ...  hjorthActivity13  hjorthActivity14  \\\n",
            "0      1.025598  1.026628  1.026628  ...          0.342652          0.553720   \n",
            "1      1.027142  1.026628  1.027142  ...          0.637546          0.845208   \n",
            "2      1.026628  1.026628  1.026371  ...          0.726135          0.311757   \n",
            "3      1.025598  1.026628  1.026371  ...          0.597512          0.556655   \n",
            "4      1.025081  1.026628  1.025856  ...          1.037500          0.626505   \n",
            "...         ...       ...       ...  ...               ...               ...   \n",
            "28339  1.024045  1.024045  1.026628  ...          0.559344          0.939575   \n",
            "28340  1.021963  1.021440  1.026628  ...         45.509049          0.944880   \n",
            "28341  1.019075  1.020129  1.026628  ...          0.724748          0.981284   \n",
            "28342  1.023526  1.021702  1.026628  ...          0.368022          0.960257   \n",
            "28343  1.005304  1.005580  1.005304  ...          0.068407          0.244710   \n",
            "\n",
            "       hjorthActivity15  hjorthActivity16  hjorthActivity17  hjorthActivity18  \\\n",
            "0              0.789203          0.830382          0.070745          0.562208   \n",
            "1              0.591822          0.885271          0.056386          0.567465   \n",
            "2              0.503166          0.845861          0.068665          0.275606   \n",
            "3              0.624270          0.871739          0.072619          0.609055   \n",
            "4              0.747394          0.858522          0.096654          0.652383   \n",
            "...                 ...               ...               ...               ...   \n",
            "28339          0.672366          0.703586          0.583271          0.883000   \n",
            "28340          0.965127          0.785416          0.468639          1.324141   \n",
            "28341          0.946794          1.527015          1.111463          0.698030   \n",
            "28342          0.745978          0.787470          1.713865          0.690877   \n",
            "28343          0.196636          0.019369          0.112196         47.153660   \n",
            "\n",
            "       hjorthActivity19  hjorthActivity20  hjorthActivity21  hjorthActivity22  \n",
            "0              0.487474          0.461642          0.556761          1.677465  \n",
            "1              1.229121          0.412308          0.347055          0.754927  \n",
            "2              1.897297          0.271671          0.180197          0.658217  \n",
            "3              1.325099          0.287102          0.345554          0.718895  \n",
            "4              0.585153          0.313660          0.537871          1.277580  \n",
            "...                 ...               ...               ...               ...  \n",
            "28339          0.465374          0.399981          0.939815          1.131835  \n",
            "28340          0.480518          0.514603          0.516706          0.599368  \n",
            "28341          1.111871          0.537384          0.610848          1.048749  \n",
            "28342          0.766807          0.421118          0.765015          1.066146  \n",
            "28343          0.064425          0.482556          0.305593          1.547091  \n",
            "\n",
            "[28344 rows x 47 columns] [0 0 0 ... 6 6 6]\n"
          ]
        }
      ],
      "source": [
        "epilepsy_data = pd.read_csv('/content/original_epilepsy_types_new - original_epilepsy_types_new.csv.csv')\n",
        "epilepsy_data =epilepsy_data.drop(['Unnamed: 0'],axis=1)\n",
        "epilepsy_data.columns=['PFD0', 'PFD1', 'PFD2', 'PFD3', 'PFD4', 'PFD5', 'PFD6', 'PFD7', 'PFD8',\n",
        "       'PFD9', 'PFD10', 'PFD11', 'PFD12', 'PFD13', 'PFD14', 'PFD15', 'PFD16',\n",
        "       'PFD17', 'PFD18', 'PFD19', 'PFD20', 'PFD21', 'PFD22', 'DTW',\n",
        "       'hjorthActivity0', 'hjorthActivity1', 'hjorthActivity2',\n",
        "       'hjorthActivity3', 'hjorthActivity4', 'hjorthActivity5',\n",
        "       'hjorthActivity6', 'hjorthActivity7', 'hjorthActivity8',\n",
        "       'hjorthActivity9', 'hjorthActivity10', 'hjorthActivity11',\n",
        "       'hjorthActivity12', 'hjorthActivity13', 'hjorthActivity14',\n",
        "       'hjorthActivity15', 'hjorthActivity16', 'hjorthActivity17',\n",
        "       'hjorthActivity18', 'hjorthActivity19', 'hjorthActivity20',\n",
        "       'hjorthActivity21', 'hjorthActivity22','Label']\n",
        "x=epilepsy_data[['PFD0', 'PFD1', 'PFD2', 'PFD3', 'PFD4', 'PFD5', 'PFD6', 'PFD7', 'PFD8',\n",
        "       'PFD9', 'PFD10', 'PFD11', 'PFD12', 'PFD13', 'PFD14', 'PFD15', 'PFD16',\n",
        "       'PFD17', 'PFD18', 'PFD19', 'PFD20', 'PFD21', 'PFD22', 'DTW',\n",
        "       'hjorthActivity0', 'hjorthActivity1', 'hjorthActivity2',\n",
        "       'hjorthActivity3', 'hjorthActivity4', 'hjorthActivity5',\n",
        "       'hjorthActivity6', 'hjorthActivity7', 'hjorthActivity8',\n",
        "       'hjorthActivity9', 'hjorthActivity10', 'hjorthActivity11',\n",
        "       'hjorthActivity12', 'hjorthActivity13', 'hjorthActivity14',\n",
        "       'hjorthActivity15', 'hjorthActivity16', 'hjorthActivity17',\n",
        "       'hjorthActivity18', 'hjorthActivity19', 'hjorthActivity20',\n",
        "       'hjorthActivity21', 'hjorthActivity22']]\n",
        "y = epilepsy_data.loc[:,'Label'].values\n",
        "print(x,y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QIOAtx35JUMg"
      },
      "source": [
        "Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5oLAyuVVtM6p"
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function\n",
        "import pandas as pd\n",
        "import eeglib\n",
        "from eeglib.helpers import EDFHelper\n",
        "import mne\n",
        "from collections import Counter\n",
        "import statistics\n",
        "import streamlit as st\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import svm\n",
        "from sklearn.metrics import accuracy_score\n",
        "import os\n",
        "import time\n",
        "import random\n",
        "import glob\n",
        "import librosa\n",
        "import numpy as np\n",
        "import librosa.display\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from numpy import loadtxt\n",
        "import seaborn as sn\n",
        "import pandas as pd\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras.layers import GRU,LSTM\n",
        "from keras.models import Sequential\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from keras.utils import np_utils\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.callbacks import  ModelCheckpoint\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from keras.layers.core import Dense, Activation\n",
        "from keras.layers.core import Dropout\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.layers import Dropout\n",
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N70uzX2YtM92",
        "outputId": "305bdd24-743e-4dde-af60-6c94def8b0d1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "709/709 [==============================] - 8s 7ms/step - loss: 1.4386 - accuracy: 0.4795 - val_loss: 0.9255 - val_accuracy: 0.7343\n",
            "Epoch 2/50\n",
            "709/709 [==============================] - 5s 7ms/step - loss: 0.7923 - accuracy: 0.7429 - val_loss: 0.5764 - val_accuracy: 0.8375\n",
            "Epoch 3/50\n",
            "709/709 [==============================] - 4s 6ms/step - loss: 0.5772 - accuracy: 0.8232 - val_loss: 0.4216 - val_accuracy: 0.8857\n",
            "Epoch 4/50\n",
            "709/709 [==============================] - 4s 5ms/step - loss: 0.4677 - accuracy: 0.8550 - val_loss: 0.3447 - val_accuracy: 0.9044\n",
            "Epoch 5/50\n",
            "709/709 [==============================] - 6s 8ms/step - loss: 0.4082 - accuracy: 0.8758 - val_loss: 0.2997 - val_accuracy: 0.9169\n",
            "Epoch 6/50\n",
            "709/709 [==============================] - 6s 8ms/step - loss: 0.3654 - accuracy: 0.8855 - val_loss: 0.2708 - val_accuracy: 0.9180\n",
            "Epoch 7/50\n",
            "709/709 [==============================] - 9s 12ms/step - loss: 0.3405 - accuracy: 0.8952 - val_loss: 0.2477 - val_accuracy: 0.9259\n",
            "Epoch 8/50\n",
            "709/709 [==============================] - 6s 9ms/step - loss: 0.3140 - accuracy: 0.9015 - val_loss: 0.2283 - val_accuracy: 0.9291\n",
            "Epoch 9/50\n",
            "709/709 [==============================] - 6s 8ms/step - loss: 0.2974 - accuracy: 0.9100 - val_loss: 0.2132 - val_accuracy: 0.9353\n",
            "Epoch 10/50\n",
            "709/709 [==============================] - 4s 6ms/step - loss: 0.2823 - accuracy: 0.9103 - val_loss: 0.2043 - val_accuracy: 0.9391\n",
            "Epoch 11/50\n",
            "709/709 [==============================] - 3s 5ms/step - loss: 0.2667 - accuracy: 0.9174 - val_loss: 0.1904 - val_accuracy: 0.9418\n",
            "Epoch 12/50\n",
            "709/709 [==============================] - 3s 5ms/step - loss: 0.2545 - accuracy: 0.9202 - val_loss: 0.1788 - val_accuracy: 0.9453\n",
            "Epoch 13/50\n",
            "709/709 [==============================] - 5s 8ms/step - loss: 0.2408 - accuracy: 0.9240 - val_loss: 0.1692 - val_accuracy: 0.9501\n",
            "Epoch 14/50\n",
            "709/709 [==============================] - 4s 5ms/step - loss: 0.2332 - accuracy: 0.9270 - val_loss: 0.1623 - val_accuracy: 0.9485\n",
            "Epoch 15/50\n",
            "709/709 [==============================] - 6s 9ms/step - loss: 0.2227 - accuracy: 0.9283 - val_loss: 0.1547 - val_accuracy: 0.9513\n",
            "Epoch 16/50\n",
            "709/709 [==============================] - 7s 10ms/step - loss: 0.2118 - accuracy: 0.9323 - val_loss: 0.1480 - val_accuracy: 0.9543\n",
            "Epoch 17/50\n",
            "709/709 [==============================] - 5s 6ms/step - loss: 0.2033 - accuracy: 0.9354 - val_loss: 0.1431 - val_accuracy: 0.9559\n",
            "Epoch 18/50\n",
            "709/709 [==============================] - 4s 6ms/step - loss: 0.1962 - accuracy: 0.9388 - val_loss: 0.1353 - val_accuracy: 0.9608\n",
            "Epoch 19/50\n",
            "709/709 [==============================] - 7s 9ms/step - loss: 0.1888 - accuracy: 0.9402 - val_loss: 0.1291 - val_accuracy: 0.9628\n",
            "Epoch 20/50\n",
            "709/709 [==============================] - 6s 8ms/step - loss: 0.1806 - accuracy: 0.9427 - val_loss: 0.1249 - val_accuracy: 0.9619\n",
            "Epoch 21/50\n",
            "709/709 [==============================] - 6s 9ms/step - loss: 0.1802 - accuracy: 0.9416 - val_loss: 0.1222 - val_accuracy: 0.9651\n",
            "Epoch 22/50\n",
            "709/709 [==============================] - 4s 5ms/step - loss: 0.1705 - accuracy: 0.9453 - val_loss: 0.1179 - val_accuracy: 0.9658\n",
            "Epoch 23/50\n",
            "709/709 [==============================] - 3s 5ms/step - loss: 0.1659 - accuracy: 0.9469 - val_loss: 0.1124 - val_accuracy: 0.9677\n",
            "Epoch 24/50\n",
            "709/709 [==============================] - 4s 6ms/step - loss: 0.1637 - accuracy: 0.9486 - val_loss: 0.1082 - val_accuracy: 0.9681\n",
            "Epoch 25/50\n",
            "709/709 [==============================] - 5s 7ms/step - loss: 0.1540 - accuracy: 0.9512 - val_loss: 0.1062 - val_accuracy: 0.9688\n",
            "Epoch 26/50\n",
            "709/709 [==============================] - 4s 5ms/step - loss: 0.1502 - accuracy: 0.9524 - val_loss: 0.1026 - val_accuracy: 0.9707\n",
            "Epoch 27/50\n",
            "709/709 [==============================] - 4s 6ms/step - loss: 0.1452 - accuracy: 0.9537 - val_loss: 0.1009 - val_accuracy: 0.9711\n",
            "Epoch 28/50\n",
            "709/709 [==============================] - 5s 8ms/step - loss: 0.1405 - accuracy: 0.9560 - val_loss: 0.0988 - val_accuracy: 0.9698\n",
            "Epoch 29/50\n",
            "709/709 [==============================] - 4s 5ms/step - loss: 0.1371 - accuracy: 0.9563 - val_loss: 0.0967 - val_accuracy: 0.9720\n",
            "Epoch 30/50\n",
            "709/709 [==============================] - 4s 5ms/step - loss: 0.1384 - accuracy: 0.9561 - val_loss: 0.0927 - val_accuracy: 0.9735\n",
            "Epoch 31/50\n",
            "709/709 [==============================] - 4s 6ms/step - loss: 0.1331 - accuracy: 0.9571 - val_loss: 0.0908 - val_accuracy: 0.9737\n",
            "Epoch 32/50\n",
            "709/709 [==============================] - 4s 6ms/step - loss: 0.1315 - accuracy: 0.9580 - val_loss: 0.0905 - val_accuracy: 0.9739\n",
            "Epoch 33/50\n",
            "709/709 [==============================] - 3s 5ms/step - loss: 0.1259 - accuracy: 0.9599 - val_loss: 0.0863 - val_accuracy: 0.9746\n",
            "Epoch 34/50\n",
            "709/709 [==============================] - 4s 5ms/step - loss: 0.1242 - accuracy: 0.9612 - val_loss: 0.0851 - val_accuracy: 0.9760\n",
            "Epoch 35/50\n",
            "709/709 [==============================] - 5s 7ms/step - loss: 0.1201 - accuracy: 0.9601 - val_loss: 0.0827 - val_accuracy: 0.9758\n",
            "Epoch 36/50\n",
            "709/709 [==============================] - 4s 5ms/step - loss: 0.1160 - accuracy: 0.9635 - val_loss: 0.0813 - val_accuracy: 0.9764\n",
            "Epoch 37/50\n",
            "709/709 [==============================] - 3s 5ms/step - loss: 0.1148 - accuracy: 0.9632 - val_loss: 0.0790 - val_accuracy: 0.9776\n",
            "Epoch 38/50\n",
            "709/709 [==============================] - 3s 5ms/step - loss: 0.1119 - accuracy: 0.9638 - val_loss: 0.0791 - val_accuracy: 0.9785\n",
            "Epoch 39/50\n",
            "709/709 [==============================] - 5s 7ms/step - loss: 0.1161 - accuracy: 0.9638 - val_loss: 0.0765 - val_accuracy: 0.9787\n",
            "Epoch 40/50\n",
            "709/709 [==============================] - 3s 5ms/step - loss: 0.1084 - accuracy: 0.9644 - val_loss: 0.0762 - val_accuracy: 0.9788\n",
            "Epoch 41/50\n",
            "709/709 [==============================] - 4s 5ms/step - loss: 0.1067 - accuracy: 0.9644 - val_loss: 0.0753 - val_accuracy: 0.9787\n",
            "Epoch 42/50\n",
            "709/709 [==============================] - 4s 5ms/step - loss: 0.1050 - accuracy: 0.9665 - val_loss: 0.0720 - val_accuracy: 0.9794\n",
            "Epoch 43/50\n",
            "709/709 [==============================] - 5s 7ms/step - loss: 0.1075 - accuracy: 0.9652 - val_loss: 0.0718 - val_accuracy: 0.9792\n",
            "Epoch 44/50\n",
            "709/709 [==============================] - 4s 5ms/step - loss: 0.1027 - accuracy: 0.9676 - val_loss: 0.0717 - val_accuracy: 0.9788\n",
            "Epoch 45/50\n",
            "709/709 [==============================] - 4s 5ms/step - loss: 0.1030 - accuracy: 0.9660 - val_loss: 0.0723 - val_accuracy: 0.9794\n",
            "Epoch 46/50\n",
            "709/709 [==============================] - 5s 7ms/step - loss: 0.0993 - accuracy: 0.9690 - val_loss: 0.0713 - val_accuracy: 0.9788\n",
            "Epoch 47/50\n",
            "709/709 [==============================] - 4s 6ms/step - loss: 0.1003 - accuracy: 0.9675 - val_loss: 0.0704 - val_accuracy: 0.9801\n",
            "Epoch 48/50\n",
            "709/709 [==============================] - 4s 5ms/step - loss: 0.0973 - accuracy: 0.9697 - val_loss: 0.0695 - val_accuracy: 0.9794\n",
            "Epoch 49/50\n",
            "709/709 [==============================] - 4s 5ms/step - loss: 0.0942 - accuracy: 0.9704 - val_loss: 0.0685 - val_accuracy: 0.9806\n",
            "Epoch 50/50\n",
            "709/709 [==============================] - 5s 7ms/step - loss: 0.0944 - accuracy: 0.9688 - val_loss: 0.0674 - val_accuracy: 0.9809\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(x)\n",
        "x = scaler.transform(x)\n",
        "from keras.utils import to_categorical\n",
        "y = to_categorical(y)\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 42)\n",
        "x_train1 = np.reshape(x_train, (x_train.shape[0],1,x.shape[1]))\n",
        "x_test1 = np.reshape(x_test, (x_test.shape[0],1,x.shape[1]))\n",
        "model = Sequential()\n",
        "model.add(LSTM(64, input_shape=(1,47),activation=\"sigmoid\",return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(32,activation=\"sigmoid\"))\n",
        "model.add(Dropout(0.2))\n",
        "#model.add(LSTM(100,return_sequences=True))\n",
        "#model.add(Dropout(0.2))\n",
        "#model.add(LSTM(50))\n",
        "#model.add(Dropout(0.2))\n",
        "model.add(Dense(7, activation='sigmoid'))\n",
        "from keras.optimizers import SGD\n",
        "model.compile(loss = 'categorical_crossentropy', optimizer = \"adam\", metrics = ['accuracy'])\n",
        "\n",
        "model.fit(x_train1, y_train, epochs = 50, validation_data= (x_test1, y_test))\n",
        "model.save('my_lstm_model.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rj3XAnF8LMF4"
      },
      "source": [
        "Accuracy Score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eXNXFzy8yktA"
      },
      "outputs": [],
      "source": [
        "# accuracy score on training data\n",
        "x_train_prediction = model.predict(x_test1)\n",
        "training_data_accuracy = accuracy_score(y_test, x_train_prediction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9mB-q8_4yz7q",
        "outputId": "e95095af-1076-479c-d4de-6bd99ffb678d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy score of training data :  0.9100305148144502\n"
          ]
        }
      ],
      "source": [
        "print('Accuracy score of training data : ', training_data_accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L1srlxtEFYfN"
      },
      "source": [
        "1  --> Parkinson's Positive\n",
        "\n",
        "0 --> Healthy\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QlR4JG4YMfOR"
      },
      "source": [
        "Building a Predictive System"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w0FjSoO1MGBU"
      },
      "outputs": [],
      "source": [
        "def prediction(dataframe):   \n",
        " \n",
        "    # Making predictions \n",
        "    \n",
        "    loaded_model = load_model('my_lstm_model.h5')\n",
        "    prediction1 = loaded_model.predict(dataframe)\n",
        "    predict_classes = np.argmax(prediction1,axis=1)\n",
        "    print(prediction1)\n",
        "    print(predict_classes)\n",
        "    prediction2 = statistics.mode(predict_classes)\n",
        "   \n",
        "     \n",
        "    if (prediction2 == 0):\n",
        "        pred = 'Dis1 Generalised Epilepsy'\n",
        "    elif (prediction2 == 1):\n",
        "        pred = 'Dis3 Generalised Epilepsy'\n",
        "    elif (prediction2 == 2):\n",
        "        pred = 'Delta Generalised Epilepsy'\n",
        "    elif (prediction2 == 3):\n",
        "        pred = 'Single burst Generalised Epilepsy'\n",
        "    elif (prediction2 == 4):\n",
        "        pred = 'Temporal Epilepsy'\n",
        "    elif (prediction2 == 5):\n",
        "        pred = 'Frontocentral Epilepsy'\n",
        "    else:\n",
        "        pred = 'Frontopolar Epilepsy'\n",
        "    return pred\n",
        "      "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8CtV-Ybsibzq"
      },
      "source": [
        "Disease Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sDfRV3nvif4x"
      },
      "source": [
        "Early Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x3SGx09KKzKs"
      },
      "outputs": [],
      "source": [
        "!pip install scikit-learn\n",
        "!pip install eeglib\n",
        "!pip install mne\n",
        "!pip install pyEDFlib\n",
        "!pip install EDFlib-Python\n",
        "!pip install scikit-learn --pre\n",
        "!pip install eeglib\n",
        "import eeglib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FE04TtA8RPyO"
      },
      "outputs": [],
      "source": [
        "\n",
        "!pip install tensorflow==2.11.0\n",
        "import tensorflow as tf\n",
        "# keras_clf = KerasClassifier(model = model, optimizer=tf.keras.optimizers.Adam(), epochs=100, verbose=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZT5Drt_FKzOR"
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function\n",
        "import pandas as pd\n",
        "\n",
        "from eeglib.helpers import EDFHelper\n",
        "import mne\n",
        "from collections import Counter\n",
        "import statistics\n",
        "# import streamlit as st\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import svm\n",
        "from sklearn.metrics import accuracy_score\n",
        "import os\n",
        "import time\n",
        "import random\n",
        "import glob\n",
        "import librosa\n",
        "import numpy as np\n",
        "import librosa.display\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from numpy import loadtxt\n",
        "import seaborn as sn\n",
        "import pandas as pd\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from keras.utils import np_utils\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras.layers import GRU,LSTM\n",
        "from tensorflow.keras import layers\n",
        "tf.keras.backend.clear_session()\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.callbacks import  ModelCheckpoint\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from keras.layers.core import Dense, Activation\n",
        "from keras.layers.core import Dropout\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.layers import Dropout\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KjtYMfADLO3z"
      },
      "source": [
        "LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cPhuvslnKzRZ"
      },
      "outputs": [],
      "source": [
        "epilepsy_data = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/final.csv')\n",
        "epilepsy_data =epilepsy_data.drop(['Unnamed: 0'],axis=1)\n",
        "epilepsy_data.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IP2FFLUdKzU2"
      },
      "outputs": [],
      "source": [
        "\n",
        "x=epilepsy_data[['Mean','Std','Ptp','Var','Minim','Maxim','Argminim','Argmaxim','Mean_square','RMS','Abs_diffs_signal',\n",
        "                           'Skewness','Kurtosis','Spectral_centroid','Spectral_rolloff','Spectral_contrast','Spectral_bandwidth','Spectral_flatness','DWT','CorrelationDimension',\n",
        "                           'Zero_crossing_rate','SpectralEntropy','PFD']]\n",
        "y = epilepsy_data.loc[:,'Label'].values\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V8ltkr9kKzXV"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(x)\n",
        "x = scaler.transform(x)\n",
        "from keras.utils import to_categorical\n",
        "y = to_categorical(y)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "biL5JOv2Lmp6"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 42)\n",
        "x_train1 = np.reshape(x_train, (x_train.shape[0],1,x.shape[1]))\n",
        "x_test1 = np.reshape(x_test, (x_test.shape[0],1,x.shape[1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J-T61aWiLoj_"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "# model.add(LSTM(128, input_shape=(1,18),activation=\"sigmoid\",return_sequences=True))\n",
        "# model.add(Dropout(0.3))\n",
        "model.add(LSTM(64, input_shape=(1,23),activation=\"relu\",return_sequences=True))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(LSTM(16,activation=\"relu\"))\n",
        "model.add(Dropout(0.2))\n",
        "#model.add(LSTM(100,return_sequences=True))\n",
        "#model.add(Dropout(0.2))\n",
        "#model.add(LSTM(50))\n",
        "#model.add(Dropout(0.2))\n",
        "model.add(Dense(3, activation='sigmoid'))\n",
        "model.add(layers.Activation('softmax'))\n",
        "opt = keras.optimizers.Adam(learning_rate=0.01)\n",
        "from keras.optimizers import SGD\n",
        "model.compile(loss = 'categorical_crossentropy', optimizer = opt, metrics = ['accuracy'])\n",
        "\n",
        "history = model.fit(x_train1, y_train, epochs = 100, validation_data= (x_test1, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XT4jCnTPL0O3"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "target_names = ['0', '1', '2']\n",
        "pred = model.predict(x_test1)\n",
        "predict_classes = np.argmax(pred,axis=1)\n",
        "expected_classes = np.argmax(y_test,axis=1)\n",
        "print(expected_classes.shape)\n",
        "print(predict_classes.shape)\n",
        "print(classification_report(expected_classes, predict_classes, target_names=target_names))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mlAKsXHJL0VP",
        "outputId": "cb7abc1f-e27a-45ef-e71b-699abc484a17"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 0s 3ms/step\n",
            "(84,)\n",
            "(84,)\n",
            "Training Accuracy: 0.8809523809523809\n",
            "Precision: 0.875\n",
            "Recall: 0.8859180035650623\n",
            "F1 Score: 0.8784513993003499\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "pred = model.predict(x_test1)\n",
        "predict_classes = np.argmax(pred,axis=1)\n",
        "expected_classes = np.argmax(y_test,axis=1)\n",
        "print(expected_classes.shape)\n",
        "print(predict_classes.shape)\n",
        "correct = accuracy_score(expected_classes,predict_classes)\n",
        "correct1 = precision_score(expected_classes,predict_classes,average='macro')\n",
        "correct2 = recall_score(expected_classes,predict_classes,average='macro')\n",
        "correct3 = f1_score(expected_classes,predict_classes,average='macro')\n",
        "print(f\"Training Accuracy: {correct}\")\n",
        "print(f\"Precision: {correct1}\")\n",
        "print(f\"Recall: {correct2}\")\n",
        "print(f\"F1 Score: {correct3}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "be2SHy61L-1P"
      },
      "outputs": [],
      "source": [
        "acc_train = history.history['loss']\n",
        "acc_val = history.history['val_loss']\n",
        "epochs = range(1,101)\n",
        "plt.plot(epochs, acc_train, 'g', label='Training accuracy')\n",
        "plt.plot(epochs, acc_val, 'b', label='Validation accuracy')\n",
        "plt.title('Training and Validation accuracies')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "\n",
        "plt.legend()\n",
        "#plt.show()\n",
        "plt.savefig(\"Accuracy_plot_LSTM.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R-1z9XwUME9F"
      },
      "outputs": [],
      "source": [
        "loss_train = history.history['loss']\n",
        "loss_val = history.history['val_loss']\n",
        "epochs = range(1,101)\n",
        "plt.plot(epochs, loss_train, 'g', label='Training loss')\n",
        "plt.plot(epochs, loss_val, 'b', label='Validation loss')\n",
        "plt.title('Training and Validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "#plt.show()\n",
        "plt.savefig(\"Loss_plot_LSTM.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GBS-QT2RO3nn"
      },
      "source": [
        "Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Pan8F18MgQW",
        "outputId": "1559e25f-9cfe-4933-d49b-693a865f3f07"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'pyeeg'...\n",
            "remote: Enumerating objects: 210, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 210 (delta 0), reused 0 (delta 0), pack-reused 207\u001b[K\n",
            "Receiving objects: 100% (210/210), 119.45 KiB | 2.02 MiB/s, done.\n",
            "Resolving deltas: 100% (95/95), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/forrestbao/pyeeg.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j8Ok5cFQMzTm"
      },
      "outputs": [],
      "source": [
        "%cd pyeeg\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Za813M-AM249"
      },
      "outputs": [],
      "source": [
        "!python3 setup.py install\n",
        "!pip install nolds\n",
        "!pip install librosa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PtwxubLfM3UR"
      },
      "outputs": [],
      "source": [
        "import pyeeg\n",
        "import nolds\n",
        "import pywt\n",
        "import math\n",
        "import librosa\n",
        "\n",
        "def PFD( x ):\n",
        "\tresp = pyeeg.pfd(x)\n",
        "\treturn resp\n",
        "\n",
        "def CorrelationDimension( x ):\n",
        "\tresp = nolds.corr_dim(x,1)\n",
        "\treturn resp\n",
        "\n",
        "def DWT( x ):\n",
        "\tresp = pywt.dwt(x, 'db4')\n",
        "\treturn resp\n",
        "\n",
        "\n",
        "def SpectralEntropy( x ):\n",
        "\tfs = 128\n",
        "\tband = [1,4,8,12,30]\n",
        "\tb = pyeeg.bin_power(x,band,fs)\n",
        "\tresp = pyeeg.spectral_entropy(x,band,fs,Power_Ratio=b)\n",
        "\tresp = [0 if math.isnan(x) else x for x in resp]\n",
        "\treturn resp\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SCnzsdrvM3Xp"
      },
      "outputs": [],
      "source": [
        "from scipy import stats\n",
        "def mean(data):\n",
        "    return np.mean(data,axis=-1)\n",
        "    \n",
        "def std(data):\n",
        "    return np.std(data,axis=-1)\n",
        "\n",
        "def ptp(data):\n",
        "    return np.ptp(data,axis=-1)\n",
        "\n",
        "def var(data):\n",
        "        return np.var(data,axis=-1)\n",
        "\n",
        "def minim(data):\n",
        "      return np.min(data,axis=-1)\n",
        "\n",
        "\n",
        "def maxim(data):\n",
        "      return np.max(data,axis=-1)\n",
        "\n",
        "def argminim(data):\n",
        "      return np.argmin(data,axis=-1)\n",
        "\n",
        "\n",
        "def argmaxim(data):\n",
        "      return np.argmax(data,axis=-1)\n",
        "\n",
        "def mean_square(data):\n",
        "      return np.mean(data**2,axis=-1)\n",
        "\n",
        "def rms(data): #root mean square\n",
        "      return  np.sqrt(np.mean(data**2,axis=-1))  \n",
        "\n",
        "def abs_diffs_signal(data):\n",
        "    return np.sum(np.abs(np.diff(data,axis=-1)),axis=-1)\n",
        "\n",
        "\n",
        "def skewness(data):\n",
        "    return stats.skew(data,axis=-1)\n",
        "\n",
        "def kurtosis(data):\n",
        "    return stats.kurtosis(data,axis=-1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o9uEgvEHM3a5",
        "outputId": "e32c88c5-5c14-424f-e062-b93ca16ad200"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "869ZZ-zrNJop"
      },
      "outputs": [],
      "source": [
        "import scipy.io\n",
        "import numpy as np\n",
        "import glob\n",
        "import scipy.io\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "mat1 = scipy.io.loadmat('/content/drive/MyDrive/Colab Notebooks/EEG Epilepsy Datasets/Test/interictal/interictal40.mat')\n",
        "value1 = mat1['interictal']\n",
        "data1 = np.array(value1)\n",
        "mat2 = scipy.io.loadmat('/content/drive/MyDrive/Colab Notebooks/EEG Epilepsy Datasets/Test/ictal/ictal45.mat')\n",
        "value2 = mat2['ictal']\n",
        "data2 = np.array(value2)\n",
        "mat3 = scipy.io.loadmat('/content/drive/MyDrive/Colab Notebooks/EEG Epilepsy Datasets/Test/preictal/preictal40.mat')\n",
        "value3 = mat3['preictal']\n",
        "data3 = np.array(value3)\n",
        "mat4 = scipy.io.loadmat('/content/drive/MyDrive/Colab Notebooks/EEG Epilepsy Datasets/Test/interictal/interictal38.mat')\n",
        "value4 = mat4['interictal']\n",
        "data4 = np.array(value4)\n",
        "mat5 = scipy.io.loadmat('/content/drive/MyDrive/Colab Notebooks/EEG Epilepsy Datasets/Test/preictal/preictal45.mat')\n",
        "value5 = mat5['preictal']\n",
        "data5 = np.array(value5)\n",
        "mat6 = scipy.io.loadmat('/content/drive/MyDrive/Colab Notebooks/EEG Epilepsy Datasets/Test/ictal/ictal50.mat')\n",
        "value6 = mat6['ictal']\n",
        "data6 = np.array(value6)\n",
        "list1 = [data1,data2,data3,data4,data5,data6]\n",
        "signal = np.concatenate([np.expand_dims(i,axis=0) for i in list1 ])\n",
        "result = signal.ravel()\n",
        "print(result)\n",
        "result.shape\n",
        "\n",
        "\n",
        "df = pd.DataFrame(columns=['Mean','Std','Ptp','Var','Minim','Maxim','Argminim','Argmaxim','Mean_square','RMS','Abs_diffs_signal',\n",
        "                           'Skewness','Kurtosis','Spectral_centroid','Spectral_rolloff','Spectral_contrast','Spectral_bandwidth','Spectral_flatness','DWT','CorrelationDimension',\n",
        "                           'Zero_crossing_rate','SpectralEntropy','PFD'])\n",
        "result=result.flatten()\n",
        "a=0\n",
        "b=1024\n",
        "while b<=6144:\n",
        "     o=[]\n",
        "     for i in range(a,b):\n",
        "       o.append(result[i])\n",
        "     o1=np.array(o)\n",
        "     convertedArray = o1.astype(np.float)\n",
        "     df2={'Mean':mean(o1),'Std':std(o1),'Ptp':ptp(o1),'Var':var(o1),'Minim':minim(o1),'Maxim':maxim(o1),'Argminim':argminim(o1),'Argmaxim':argmaxim(o1),\n",
        "       'Mean_square':mean_square(o1),'RMS':rms(o1),'Abs_diffs_signal':abs_diffs_signal(o1),'Skewness':skewness(o1),'Kurtosis':kurtosis(o1),'Spectral_centroid':librosa.feature.spectral_centroid(y=convertedArray)[0][0],\n",
        "       'Spectral_rolloff':librosa.feature.spectral_rolloff(y=convertedArray)[0][0],'Spectral_contrast':librosa.feature.spectral_contrast(y=convertedArray)[0][0],\n",
        "       'Spectral_bandwidth':librosa.feature.spectral_bandwidth(y=convertedArray)[0][0],'Spectral_flatness':librosa.feature.spectral_flatness(y=convertedArray)[0][0],\n",
        "       'DWT':np.mean(DWT(o1),axis=-1)[0],'CorrelationDimension':CorrelationDimension(o1),\n",
        "     'Zero_crossing_rate':librosa.feature.zero_crossing_rate(y=convertedArray)[0][0],'SpectralEntropy':np.mean(SpectralEntropy(o1),axis=-1),'PFD':PFD(o1)}\n",
        "     df.loc[len(df)] = df2\n",
        "     a+=1024\n",
        "     b+=1024\n",
        "   #df = df.append(df2, ignore_index = True)\n",
        "df.to_csv('preictal.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ue0ByJ_ONgYV",
        "outputId": "174d0bae-43b7-4319-bb9e-c1d623b7dd89"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 18ms/step\n"
          ]
        }
      ],
      "source": [
        "\n",
        "dataframe=df[['Mean','Std','Ptp','Var','Minim','Maxim','Argminim','Argmaxim','Mean_square','RMS','Abs_diffs_signal',\n",
        "                           'Skewness','Kurtosis','Spectral_centroid','Spectral_rolloff','Spectral_contrast','Spectral_bandwidth','Spectral_flatness','DWT','CorrelationDimension'\n",
        "            ,'Zero_crossing_rate','SpectralEntropy','PFD']]\n",
        "\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(dataframe)\n",
        "dataframe = scaler.transform(dataframe)\n",
        "dataframe1 = np.reshape(dataframe, (dataframe.shape[0],1,dataframe.shape[1]))\n",
        "dataframe1.shape\n",
        "rr = model.predict(dataframe1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w2hPEoGeNVYX",
        "outputId": "4c5cc584-6439-4eec-d67c-f5013ef5376e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicted:  [1 2 0 1 1 2]\n"
          ]
        }
      ],
      "source": [
        "# print('Original:  ',np.array([0,0,0,0,2,2,2,2,2,2,2,2,0,0,0,0,2,2,2,2,1,1,1,1]))\n",
        "expected_classes = np.argmax(rr,axis=1)\n",
        "print('Predicted: ',expected_classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DwgwvxfmQLSz"
      },
      "source": [
        "Predictive system"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zvsFHaUcQOGT"
      },
      "outputs": [],
      "source": [
        "input_data = (1.022224036,1.027655534,1.026371185,1.026371185,1.026628492,1.026371185,1.026371185,1.024563855,1.027142449,1.026113658,1.026371185,1.026628492,1.023266214,1.026628492,1.02688558,1.026628492,1.031223035,1.023526192,1.025339754,1.02482271,1.02688558,1.027399101,1.020916175,144.26233,0.784223518,0.447766546,0.694166247,0.231925094,0.736146972,0.809544556,0.75158713,0.944293304,0.513480739,0.908025389,0.737497691,0.263564365,0.216937721,0.856380414,0.411747359,4.848634104,0.080859415,1.052120272,0.461157591,0.685372056,0.676203895,0.558924926,1.172187715)\n",
        "\n",
        "input_data_as_numpy_array = np.asarray(input_data)\n",
        "input_data_reshaped = input_data_as_numpy_array.reshape(1,-1)\n",
        "prediction = model.predict(input_data_reshaped)\n",
        "print(prediction)\n",
        "\n",
        "\n",
        "if (prediction == 0):\n",
        "  print(\"dis1 generalized\")\n",
        "elif (prediction == 1):\n",
        "  print(\"dis3 generalized\")\n",
        "elif (prediction == 2):\n",
        "  print(\" delta generalized\")\n",
        "elif (prediction == 3):\n",
        "  print(\"single burst generalized\")\n",
        "elif (prediction == 4):\n",
        "  print(\"temporal\")\n",
        "elif (prediction == 5):\n",
        "  print(\"frontocentral\")\n",
        "elif (prediction == 6):\n",
        "  print(\"frontopolar\")\n",
        "else:\n",
        "  print(\"The Person doesnot have epilepsy\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-kaiOBbSO7jF"
      },
      "source": [
        "Model Saving"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u1lwQicdPw3W"
      },
      "outputs": [],
      "source": [
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pBvLbmXDPzYw"
      },
      "outputs": [],
      "source": [
        "filename = 'epilepsy_early.sav'\n",
        "pickle.dump(model, open(filename, 'wb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        },
        "id": "l1eaNdChO9gp",
        "outputId": "e5c3dfb7-bdc7-4158-8b10-da4e39982996"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-b337e1824339>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# pickle.dump(model, open(filename, 'wb'))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# loading the saved model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mepilepsy_early\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'epilepsy_early.sav'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/saving/pickle_utils.py\u001b[0m in \u001b[0;36mdeserialize_model_from_bytecode\u001b[0;34m(serialized_model)\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msaving_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msafe_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/saving/pickle_utils.py\u001b[0m in \u001b[0;36mdeserialize_model_from_bytecode\u001b[0;34m(serialized_model)\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;31m# serialized as a string by Dense.get_config()) will require\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;31m# a custom_object_scope.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msaving_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msafe_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/saving/saving_lib.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/saving/saving_lib.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[1;32m    240\u001b[0m             \u001b[0;31m# Construct the model from the configuration file in the archive.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mObjectSharingScope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m                 model = deserialize_keras_object(\n\u001b[0m\u001b[1;32m    243\u001b[0m                     \u001b[0mconfig_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msafe_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msafe_mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/saving/serialization_lib.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(config, custom_objects, safe_mode, **kwargs)\u001b[0m\n\u001b[1;32m    506\u001b[0m         \u001b[0mcompile_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"compile_config\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcompile_config\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 508\u001b[0;31m             \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile_from_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompile_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    509\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m\"shared_object_id\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mcompile_from_config\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m   3390\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"optimizer\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3391\u001b[0m             \u001b[0;31m# Create optimizer variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3392\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3394\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexport\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/optimizers/legacy/optimizer_v2.py\u001b[0m in \u001b[0;36m__getattribute__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    982\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hyper\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    983\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_hyper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 984\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    986\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__dir__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/optimizers/legacy/optimizer_v2.py\u001b[0m in \u001b[0;36m__getattribute__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    972\u001b[0m         \u001b[0;34m\"\"\"Overridden to support hyperparameter access.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    973\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 974\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    975\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m             \u001b[0;31m# Needed to avoid infinite recursion with __setattr__.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Adam' object has no attribute 'build'"
          ]
        }
      ],
      "source": [
        "# import pickle\n",
        "# filename = 'epilepsy_early.sav'\n",
        "# pickle.dump(model, open(filename, 'wb'))\n",
        "# loading the saved model\n",
        "epilepsy_early = pickle.load(open('epilepsy_early.sav', 'rb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uO0DkdWO3Xev",
        "outputId": "bbb9c9b3-3e19-4588-e101-2e8a2c55a182"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting streamlit_option_menu\n",
            "  Downloading streamlit_option_menu-0.3.4-py3-none-any.whl (785 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m785.2/785.2 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: streamlit>=0.63 in /usr/local/lib/python3.10/dist-packages (from streamlit_option_menu) (1.22.0)\n",
            "Requirement already satisfied: altair<5,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit_option_menu) (4.2.2)\n",
            "Requirement already satisfied: blinker>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit_option_menu) (1.6.2)\n",
            "Requirement already satisfied: cachetools>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit_option_menu) (5.3.0)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit_option_menu) (8.1.3)\n",
            "Requirement already satisfied: importlib-metadata>=1.4 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit_option_menu) (6.6.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit_option_menu) (1.22.4)\n",
            "Requirement already satisfied: packaging>=14.1 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit_option_menu) (23.1)\n",
            "Requirement already satisfied: pandas<3,>=0.25 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit_option_menu) (1.5.3)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit_option_menu) (9.5.0)\n",
            "Requirement already satisfied: protobuf<4,>=3.12 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit_option_menu) (3.20.3)\n",
            "Requirement already satisfied: pyarrow>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit_option_menu) (9.0.0)\n",
            "Requirement already satisfied: pympler>=0.9 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit_option_menu) (1.0.1)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit_option_menu) (2.8.2)\n",
            "Requirement already satisfied: requests>=2.4 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit_option_menu) (2.27.1)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit_option_menu) (13.3.4)\n",
            "Requirement already satisfied: tenacity<9,>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit_option_menu) (8.2.2)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit_option_menu) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions>=3.10.0.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit_option_menu) (4.5.0)\n",
            "Requirement already satisfied: tzlocal>=1.1 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit_option_menu) (4.3)\n",
            "Requirement already satisfied: validators>=0.2 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit_option_menu) (0.20.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit_option_menu) (3.1.31)\n",
            "Requirement already satisfied: pydeck>=0.1.dev5 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit_option_menu) (0.8.1b0)\n",
            "Requirement already satisfied: tornado>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit_option_menu) (6.3.1)\n",
            "Requirement already satisfied: watchdog in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit_option_menu) (3.0.0)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<5,>=3.2.0->streamlit>=0.63->streamlit_option_menu) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<5,>=3.2.0->streamlit>=0.63->streamlit_option_menu) (3.1.2)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<5,>=3.2.0->streamlit>=0.63->streamlit_option_menu) (4.3.3)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<5,>=3.2.0->streamlit>=0.63->streamlit_option_menu) (0.12.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.19->streamlit>=0.63->streamlit_option_menu) (4.0.10)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=1.4->streamlit>=0.63->streamlit_option_menu) (3.15.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=0.25->streamlit>=0.63->streamlit_option_menu) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil->streamlit>=0.63->streamlit_option_menu) (1.16.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.4->streamlit>=0.63->streamlit_option_menu) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.4->streamlit>=0.63->streamlit_option_menu) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.4->streamlit>=0.63->streamlit_option_menu) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.4->streamlit>=0.63->streamlit_option_menu) (3.4)\n",
            "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->streamlit>=0.63->streamlit_option_menu) (2.2.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->streamlit>=0.63->streamlit_option_menu) (2.14.0)\n",
            "Requirement already satisfied: pytz-deprecation-shim in /usr/local/lib/python3.10/dist-packages (from tzlocal>=1.1->streamlit>=0.63->streamlit_option_menu) (0.1.0.post0)\n",
            "Requirement already satisfied: decorator>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from validators>=0.2->streamlit>=0.63->streamlit_option_menu) (4.4.2)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19->streamlit>=0.63->streamlit_option_menu) (5.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair<5,>=3.2.0->streamlit>=0.63->streamlit_option_menu) (2.1.2)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<5,>=3.2.0->streamlit>=0.63->streamlit_option_menu) (23.1.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<5,>=3.2.0->streamlit>=0.63->streamlit_option_menu) (0.19.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py<3.0.0,>=2.2.0->rich>=10.11.0->streamlit>=0.63->streamlit_option_menu) (0.1.2)\n",
            "Requirement already satisfied: tzdata in /usr/local/lib/python3.10/dist-packages (from pytz-deprecation-shim->tzlocal>=1.1->streamlit>=0.63->streamlit_option_menu) (2023.3)\n",
            "Installing collected packages: streamlit_option_menu\n",
            "Successfully installed streamlit_option_menu-0.3.4\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.10/dist-packages (1.22.0)\n",
            "Requirement already satisfied: altair<5,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.2.2)\n",
            "Requirement already satisfied: blinker>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.6.2)\n",
            "Requirement already satisfied: cachetools>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.3.0)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.1.3)\n",
            "Requirement already satisfied: importlib-metadata>=1.4 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.6.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.22.4)\n",
            "Requirement already satisfied: packaging>=14.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (23.1)\n",
            "Requirement already satisfied: pandas<3,>=0.25 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.5.3)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (9.5.0)\n",
            "Requirement already satisfied: protobuf<4,>=3.12 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.20.3)\n",
            "Requirement already satisfied: pyarrow>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (9.0.0)\n",
            "Requirement already satisfied: pympler>=0.9 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.0.1)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.8.2)\n",
            "Requirement already satisfied: requests>=2.4 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.27.1)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (13.3.4)\n",
            "Requirement already satisfied: tenacity<9,>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.2.2)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions>=3.10.0.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.5.0)\n",
            "Requirement already satisfied: tzlocal>=1.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.3)\n",
            "Requirement already satisfied: validators>=0.2 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.20.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.1.31)\n",
            "Requirement already satisfied: pydeck>=0.1.dev5 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.8.1b0)\n",
            "Requirement already satisfied: tornado>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.3.1)\n",
            "Requirement already satisfied: watchdog in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.0.0)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<5,>=3.2.0->streamlit) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<5,>=3.2.0->streamlit) (3.1.2)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<5,>=3.2.0->streamlit) (4.3.3)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<5,>=3.2.0->streamlit) (0.12.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.19->streamlit) (4.0.10)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=1.4->streamlit) (3.15.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=0.25->streamlit) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil->streamlit) (1.16.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.4->streamlit) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.4->streamlit) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.4->streamlit) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.4->streamlit) (3.4)\n",
            "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->streamlit) (2.2.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->streamlit) (2.14.0)\n",
            "Requirement already satisfied: pytz-deprecation-shim in /usr/local/lib/python3.10/dist-packages (from tzlocal>=1.1->streamlit) (0.1.0.post0)\n",
            "Requirement already satisfied: decorator>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from validators>=0.2->streamlit) (4.4.2)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19->streamlit) (5.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair<5,>=3.2.0->streamlit) (2.1.2)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<5,>=3.2.0->streamlit) (23.1.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<5,>=3.2.0->streamlit) (0.19.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py<3.0.0,>=2.2.0->rich>=10.11.0->streamlit) (0.1.2)\n",
            "Requirement already satisfied: tzdata in /usr/local/lib/python3.10/dist-packages (from pytz-deprecation-shim->tzlocal>=1.1->streamlit) (2023.3)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.10/dist-packages (6.0.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting jedi\n",
            "  Downloading jedi-0.18.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from jedi) (0.8.3)\n",
            "Installing collected packages: jedi\n",
            "Successfully installed jedi-0.18.2\n"
          ]
        }
      ],
      "source": [
        "! pip install streamlit -q\n",
        "! pip install streamlit_option_menu\n",
        "! pip install --upgrade streamlit\n",
        "! pip install pyngrok\n",
        "!pip install jedi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZZo8BCnY13Yv",
        "outputId": "40295865-d30b-489b-d7ad-bd6834576e71"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ],
      "source": [
        "\n",
        "%%writefile app.py\n",
        "\n",
        "# -*- coding: utf-8 -*-\n",
        "import pickle\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "import streamlit as st\n",
        "from streamlit_option_menu import option_menu\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "# loading the saved models\n",
        "\n",
        "epilepsy_model = load_model('my_lstm_model.h5')\n",
        "#epilepsy_model = pickle.load(open('/content/epilepsy_model.sav', 'rb'))  model for early detection\n",
        "#epilepsy_model = pickle.load(open('/content/epilepsy_model.sav', 'rb'))  model for disease classification\n",
        "\n",
        "\n",
        "def generate_pdf_report(variables):\n",
        "    # Create a new PDF file\n",
        "    pdf_file = canvas.Canvas(\"Report.pdf\", pagesize=letter)\n",
        "\n",
        "    # Set the title of the report\n",
        "    report_title = \"Report\"\n",
        "\n",
        "    # Add the report title to the PDF file\n",
        "    pdf_file.setFont(\"Helvetica-Bold\", 16)\n",
        "    pdf_file.drawCentredString(300, 750, report_title)\n",
        "    pdf_file.line(30, 740, 550, 740)\n",
        "\n",
        "    # Add the variables to the PDF file\n",
        "    pdf_file.setFont(\"Helvetica\", 12)\n",
        "    y = 700\n",
        "    for name, value in variables.items():\n",
        "        pdf_file.drawString(50, y, f\"{name}: {value}\")\n",
        "        y -= 20\n",
        "\n",
        "    # Save the PDF file\n",
        "    pdf_file.save()\n",
        "    return os.path.abspath(\"Report.pdf\") \n",
        "\n",
        "# sidebar for navigation\n",
        "with st.sidebar:\n",
        "    \n",
        "    selected = option_menu('Multiple Disease Prediction System',\n",
        "                          \n",
        "                          ['Epilepsy Classification',\n",
        "                            'Disease Classification',\n",
        "                           'Early Detection',],\n",
        "                          icons=['activity','heart','person'],\n",
        "                          default_index=0)\n",
        "    \n",
        "    \n",
        "# Diabetes Prediction Page\n",
        "if (selected == 'Disease Classification'):\n",
        "    \n",
        "    # page title\n",
        "    st.title('Diabetes Prediction using ML')\n",
        "    \n",
        "    \n",
        "    Patient_id =st.text_input(\"Enter your Patient Id\")\n",
        "    gender = st.selectbox(\"Enter your gender\",[\"Male\", \"Female\"])\n",
        "    col1, col2, col3 = st.columns(3)\n",
        "    age = col2.number_input(\"Enter your age\")\n",
        "    stroke = col1.selectbox(\"Have you ever experienced a seizure?\",[\"Yes\",\"No\"])\n",
        "    uploaded_file = st.file_uploader(\"Upload the eeg (EDF)\")\n",
        "    if uploaded_file is not None :\n",
        "      with open(os.path.join(\"/content/uploaded_file\",\"patient.edf\"),\"wb\") as f: \n",
        "            f.write(uploaded_file.getbuffer())       \n",
        "    \n",
        "    \n",
        "    # code for Prediction\n",
        "    def prediction(dataframe):   \n",
        " \n",
        "    # Making predictions \n",
        "        loaded_model = load_model('my_lstm_model.h5')\n",
        "        prediction1 = loaded_model.predict(dataframe)\n",
        "        predict_classes = np.argmax(prediction1,axis=1)\n",
        "        print(prediction1)\n",
        "        print(predict_classes)\n",
        "        prediction2 = statistics.mode(predict_classes)\n",
        "      \n",
        "        \n",
        "        if (prediction2 == 0):\n",
        "            pred = 'Dis1 Generalised Epilepsy'\n",
        "        elif (prediction2 == 1):\n",
        "            pred = 'Dis3 Generalised Epilepsy'\n",
        "        elif (prediction2 == 2):\n",
        "            pred = 'Delta Generalised Epilepsy'\n",
        "        elif (prediction2 == 3):\n",
        "            pred = 'Single burst Generalised Epilepsy'\n",
        "        elif (prediction2 == 4):\n",
        "            pred = 'Temporal Epilepsy'\n",
        "        elif (prediction2 == 5):\n",
        "            pred = 'Frontocentral Epilepsy'\n",
        "        else:\n",
        "            pred = 'Frontopolar Epilepsy'\n",
        "        return pred\n",
        "    \n",
        "    # creating a button for Prediction\n",
        "    \n",
        "    if st.button(\"Predict\"):\n",
        "      st.write(\"Processing Please Wait\") \n",
        "      s1= mne.io.read_raw_edf('/content/uploaded_file/patient.edf',include=['C3',\n",
        "      'C4',\n",
        "      'Cz',\n",
        "      'F3',\n",
        "      'F4',\n",
        "      'F7',\n",
        "      'F8',\n",
        "      'Fz',\n",
        "      'Fp1',\n",
        "      'Fp2',\n",
        "      'A1',\n",
        "      'A2',\n",
        "      'O1',\n",
        "      'O2',\n",
        "      'P3',\n",
        "      'P4',\n",
        "      'T5',\n",
        "      'T6',\n",
        "      'Pz',\n",
        "      'T3',\n",
        "      'T4',\n",
        "      'ECG-LA',\n",
        "      'ECG-RA'])\n",
        "      s2 = mne.export.export_raw('/content/patient1.edf',s1,overwrite=True)\n",
        "      helper= EDFHelper(\"/content/patient1.edf\",lowpass=70, highpass=1, normalize=True, ICA=True,windowSize = 20)\n",
        "      wrapper=eeglib.wrapper.Wrapper(helper)\n",
        "      wrapper.addFeature.PFD()\n",
        "      wrapper.addFeature.DTW((0,1))\n",
        "      wrapper.addFeature.hjorthActivity()\n",
        "      data=wrapper.getAllFeatures()\n",
        "      data.to_csv('patient.csv')\n",
        "      dataframe1 = pd.read_csv('patient.csv')\n",
        "      dataframe1 = dataframe1.drop(dataframe1.columns[0],axis=1)\n",
        "      dataframe1.columns = ['PFD0', 'PFD1', 'PFD2', 'PFD3', 'PFD4', 'PFD5', 'PFD6', 'PFD7', 'PFD8',\n",
        "    'PFD9', 'PFD10', 'PFD11', 'PFD12', 'PFD13', 'PFD14', 'PFD15', 'PFD16',\n",
        "    'PFD17', 'PFD18', 'PFD19', 'PFD20', 'PFD21', 'PFD22', 'DTW',\n",
        "    'hjorthActivity0', 'hjorthActivity1', 'hjorthActivity2',\n",
        "    'hjorthActivity3', 'hjorthActivity4', 'hjorthActivity5',\n",
        "    'hjorthActivity6', 'hjorthActivity7', 'hjorthActivity8',\n",
        "    'hjorthActivity9', 'hjorthActivity10', 'hjorthActivity11',\n",
        "    'hjorthActivity12', 'hjorthActivity13', 'hjorthActivity14',\n",
        "    'hjorthActivity15', 'hjorthActivity16', 'hjorthActivity17',\n",
        "    'hjorthActivity18', 'hjorthActivity19', 'hjorthActivity20',\n",
        "    'hjorthActivity21', 'hjorthActivity22']\n",
        "      dataframe1.to_csv(\"patient_app.csv\")\n",
        "      dataframe3 = pd.read_csv('patient_app.csv')\n",
        "      dataframe2 = dataframe3.drop(dataframe3.columns[0],axis=1)\n",
        "      dataframe2 = scaler.transform(dataframe2)\n",
        "      dataframe = np.array(dataframe1.values).reshape((dataframe1.shape[0],1,47))\n",
        "      result = prediction(dataframe) \n",
        "      variables = {\"Name\": Patient_id, \"Age\": age, \"Gender\":gender, \"Have you ever experienced a seizure\":stroke, \"Result\":result} \n",
        "\n",
        "              # Display the variables in Streamlit\n",
        "              # Generate the PDF report\n",
        "      pdf_file_path = generate_pdf_report(variables)\n",
        "      with st.expander(\"Download PDF Report\"):\n",
        "              st.write(\"Click the button below to download the PDF report\")\n",
        "              st.download_button(\n",
        "                  label=\"Download Report\",\n",
        "                  data=open(pdf_file_path, \"rb\").read(),\n",
        "                  file_name=\"streamlit_variables.pdf\",\n",
        "                  mime=\"application/pdf\"\n",
        "              )  \n",
        "      st.success('Patient disease is {}'.format(result))\n",
        "      print(result)\n",
        "\n",
        "\n",
        "\n",
        "# Heart Disease Prediction Page\n",
        "if (selected == 'Early Detection'):\n",
        "    \n",
        "    # page title\n",
        "    st.title('Heart Disease Prediction using ML')\n",
        "    \n",
        "    col1, col2, col3 = st.columns(3)\n",
        "    \n",
        "    with col1:\n",
        "        age = st.text_input('Age')\n",
        "        \n",
        "    with col2:\n",
        "        sex = st.text_input('Sex')\n",
        "        \n",
        "    with col3:\n",
        "        cp = st.text_input('Chest Pain types')\n",
        "        \n",
        "    with col1:\n",
        "        trestbps = st.text_input('Resting Blood Pressure')\n",
        "        \n",
        "    with col2:\n",
        "        chol = st.text_input('Serum Cholestoral in mg/dl')\n",
        "        \n",
        "    with col3:\n",
        "        fbs = st.text_input('Fasting Blood Sugar > 120 mg/dl')\n",
        "        \n",
        "    with col1:\n",
        "        restecg = st.text_input('Resting Electrocardiographic results')\n",
        "        \n",
        "    with col2:\n",
        "        thalach = st.text_input('Maximum Heart Rate achieved')\n",
        "        \n",
        "    with col3:\n",
        "        exang = st.text_input('Exercise Induced Angina')\n",
        "        \n",
        "    with col1:\n",
        "        oldpeak = st.text_input('ST depression induced by exercise')\n",
        "        \n",
        "    with col2:\n",
        "        slope = st.text_input('Slope of the peak exercise ST segment')\n",
        "        \n",
        "    with col3:\n",
        "        ca = st.text_input('Major vessels colored by flourosopy')\n",
        "        \n",
        "    with col1:\n",
        "        thal = st.text_input('thal: 0 = normal; 1 = fixed defect; 2 = reversable defect')\n",
        "        \n",
        "        \n",
        "     \n",
        "     \n",
        "    # code for Prediction\n",
        "    heart_diagnosis = ''\n",
        "    \n",
        "    # creating a button for Prediction\n",
        "    \n",
        "    if st.button('Heart Disease Test Result'):\n",
        "        heart_prediction = heart_disease_model.predict([[age, sex, cp, trestbps, chol, fbs, restecg,thalach,exang,oldpeak,slope,ca,thal]])                          \n",
        "        \n",
        "        if (heart_prediction[0] == 1):\n",
        "          heart_diagnosis = 'The person is having heart disease'\n",
        "        else:\n",
        "          heart_diagnosis = 'The person does not have any heart disease'\n",
        "        \n",
        "    st.success(heart_diagnosis)\n",
        "        \n",
        "    \n",
        "\n",
        "# Epilepsy Classification\n",
        "if (selected == \"Epilepsy Classification\"):\n",
        "    \n",
        "    # page title\n",
        "    st.title(\"Epilepsy Classification using Deep Learning\")\n",
        "    \n",
        "    Patient_id =st.text_input(\"Enter your Patient Id\")\n",
        "    gender = st.selectbox(\"Enter your gender\",[\"Male\", \"Female\"])\n",
        "    col1, col2, col3 = st.columns(3)\n",
        "    age = col2.number_input(\"Enter your age\")\n",
        "    stroke = col1.selectbox(\"Have you ever experienced a seizure?\",[\"Yes\",\"No\"])\n",
        "    uploaded_file = st.file_uploader(\"Upload the eeg (EDF)\")\n",
        "    if uploaded_file is not None :\n",
        "      with open(os.path.join(\"/content/uploaded_file\",\"patient.edf\"),\"wb\") as f: \n",
        "            f.write(uploaded_file.getbuffer())       \n",
        "    \n",
        "    \n",
        "    # code for Prediction\n",
        "    def prediction(dataframe):   \n",
        " \n",
        "    # Making predictions \n",
        "        loaded_model = load_model('my_lstm_model.h5')\n",
        "        prediction1 = loaded_model.predict(dataframe)\n",
        "        predict_classes = np.argmax(prediction1,axis=1)\n",
        "        print(prediction1)\n",
        "        print(predict_classes)\n",
        "        prediction2 = statistics.mode(predict_classes)\n",
        "      \n",
        "        \n",
        "        if (prediction2 == 0):\n",
        "            pred = 'Dis1 Generalised Epilepsy'\n",
        "        elif (prediction2 == 1):\n",
        "            pred = 'Dis3 Generalised Epilepsy'\n",
        "        elif (prediction2 == 2):\n",
        "            pred = 'Delta Generalised Epilepsy'\n",
        "        elif (prediction2 == 3):\n",
        "            pred = 'Single burst Generalised Epilepsy'\n",
        "        elif (prediction2 == 4):\n",
        "            pred = 'Temporal Epilepsy'\n",
        "        elif (prediction2 == 5):\n",
        "            pred = 'Frontocentral Epilepsy'\n",
        "        else:\n",
        "            pred = 'Frontopolar Epilepsy'\n",
        "        return pred\n",
        "    \n",
        "    # creating a button for Prediction\n",
        "    \n",
        "    if st.button(\"Predict\"):\n",
        "      st.write(\"Processing Please Wait\") \n",
        "      s1= mne.io.read_raw_edf('/content/uploaded_file/patient.edf',include=['C3',\n",
        "      'C4',\n",
        "      'Cz',\n",
        "      'F3',\n",
        "      'F4',\n",
        "      'F7',\n",
        "      'F8',\n",
        "      'Fz',\n",
        "      'Fp1',\n",
        "      'Fp2',\n",
        "      'A1',\n",
        "      'A2',\n",
        "      'O1',\n",
        "      'O2',\n",
        "      'P3',\n",
        "      'P4',\n",
        "      'T5',\n",
        "      'T6',\n",
        "      'Pz',\n",
        "      'T3',\n",
        "      'T4',\n",
        "      'ECG-LA',\n",
        "      'ECG-RA'])\n",
        "      s2 = mne.export.export_raw('/content/patient1.edf',s1,overwrite=True)\n",
        "      helper= EDFHelper(\"/content/patient1.edf\",lowpass=70, highpass=1, normalize=True, ICA=True,windowSize = 20)\n",
        "      wrapper=eeglib.wrapper.Wrapper(helper)\n",
        "      wrapper.addFeature.PFD()\n",
        "      wrapper.addFeature.DTW((0,1))\n",
        "      wrapper.addFeature.hjorthActivity()\n",
        "      data=wrapper.getAllFeatures()\n",
        "      data.to_csv('patient.csv')\n",
        "      dataframe1 = pd.read_csv('patient.csv')\n",
        "      dataframe1 = dataframe1.drop(dataframe1.columns[0],axis=1)\n",
        "      dataframe1.columns = ['PFD0', 'PFD1', 'PFD2', 'PFD3', 'PFD4', 'PFD5', 'PFD6', 'PFD7', 'PFD8',\n",
        "    'PFD9', 'PFD10', 'PFD11', 'PFD12', 'PFD13', 'PFD14', 'PFD15', 'PFD16',\n",
        "    'PFD17', 'PFD18', 'PFD19', 'PFD20', 'PFD21', 'PFD22', 'DTW',\n",
        "    'hjorthActivity0', 'hjorthActivity1', 'hjorthActivity2',\n",
        "    'hjorthActivity3', 'hjorthActivity4', 'hjorthActivity5',\n",
        "    'hjorthActivity6', 'hjorthActivity7', 'hjorthActivity8',\n",
        "    'hjorthActivity9', 'hjorthActivity10', 'hjorthActivity11',\n",
        "    'hjorthActivity12', 'hjorthActivity13', 'hjorthActivity14',\n",
        "    'hjorthActivity15', 'hjorthActivity16', 'hjorthActivity17',\n",
        "    'hjorthActivity18', 'hjorthActivity19', 'hjorthActivity20',\n",
        "    'hjorthActivity21', 'hjorthActivity22']\n",
        "      dataframe1.to_csv(\"patient_app.csv\")\n",
        "      dataframe3 = pd.read_csv('patient_app.csv')\n",
        "      dataframe2 = dataframe3.drop(dataframe3.columns[0],axis=1)\n",
        "      dataframe2 = scaler.transform(dataframe2)\n",
        "      dataframe = np.array(dataframe1.values).reshape((dataframe1.shape[0],1,47))\n",
        "      result = prediction(dataframe) \n",
        "      variables = {\"Name\": Patient_id, \"Age\": age, \"Gender\":gender, \"Have you ever experienced a seizure\":stroke, \"Result\":result} \n",
        "\n",
        "              # Display the variables in Streamlit\n",
        "              # Generate the PDF report\n",
        "      pdf_file_path = generate_pdf_report(variables)\n",
        "      with st.expander(\"Download PDF Report\"):\n",
        "              st.write(\"Click the button below to download the PDF report\")\n",
        "              st.download_button(\n",
        "                  label=\"Download Report\",\n",
        "                  data=open(pdf_file_path, \"rb\").read(),\n",
        "                  file_name=\"streamlit_variables.pdf\",\n",
        "                  mime=\"application/pdf\"\n",
        "              )  \n",
        "      st.success('Patient disease is {}'.format(result))\n",
        "      print(result)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8totSsw_vYxj"
      },
      "outputs": [],
      "source": [
        "! pip install streamlit -q\n",
        "! pip install streamlit_option_menu\n",
        "! pip install --upgrade streamlit\n",
        "! pip install pyngrok\n",
        "!pip install jedi\n",
        "from pyngrok import ngrok"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mqDEnIydUHR8"
      },
      "outputs": [],
      "source": [
        "ngrok.kill()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_BYJRwjxylDb",
        "outputId": "f5df5c72-efbb-45a0-887f-bd6d21f22909"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:pyngrok.process.ngrok:t=2023-05-18T15:21:53+0000 lvl=warn msg=\"ngrok config file found at legacy location, move to XDG location\" xdg_path=/root/.config/ngrok/ngrok.yml legacy_path=/root/.ngrok2/ngrok.yml\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<NgrokTunnel: \"https://a1f0-34-73-53-91.ngrok.io\" -> \"http://localhost:8501\">"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from pyngrok import ngrok\n",
        " \n",
        "public_url = ngrok.connect('8501')\n",
        "public_url"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X5IWaS-1yiGP"
      },
      "outputs": [],
      "source": [
        "!streamlit run app.py &>/dev/null&"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ou9h6Ss-WV0x",
        "outputId": "e184d763-0ffd-456a-e4a2-b8e5d43cbd28"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2023-05-20 11:14:44--  http://-/\n",
            "Resolving - (-)... failed: Name or service not known.\n",
            "wget: unable to resolve host address ‘-’\n",
            "--2023-05-20 11:14:44--  http://ipv4.icanhazip.com/\n",
            "Resolving ipv4.icanhazip.com (ipv4.icanhazip.com)... 104.18.114.97, 104.18.115.97\n",
            "Connecting to ipv4.icanhazip.com (ipv4.icanhazip.com)|104.18.114.97|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 15 [text/plain]\n",
            "Saving to: ‘index.html.1’\n",
            "\n",
            "\rindex.html.1          0%[                    ]       0  --.-KB/s               \rindex.html.1        100%[===================>]      15  --.-KB/s    in 0s      \n",
            "\n",
            "2023-05-20 11:14:44 (2.44 MB/s) - ‘index.html.1’ saved [15/15]\n",
            "\n",
            "FINISHED --2023-05-20 11:14:44--\n",
            "Total wall clock time: 0.05s\n",
            "Downloaded: 1 files, 15 in 0s (2.44 MB/s)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!wget - ipv4.icanhazip.com"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CJVusoQGebAs",
        "outputId": "7ccf0fa7-ee35-4096-aa84-fa5de0dfd8b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "34.148.159.201\n"
          ]
        }
      ],
      "source": [
        "!curl ipv4.icanhazip.com"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Mes_2O-X2Do",
        "outputId": "8246429c-94c1-4ee3-a0a5-d1f2318a444a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[######............] \\ diffTrees: sill install generateActionsToTake\u001b[0m\u001b[K\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to False.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.148.159.201:8501\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[K\u001b[?25hnpx: installed 22 in 4.408s\n",
            "your url is: https://evil-insects-fall.loca.lt\n",
            "2023-05-20 11:23:12.164961: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-05-20 11:50:43.879 Session with id 1ab65434-60d1-41f2-a6f7-8b58d91c5714 is already connected! Connecting to a new session.\n",
            "2023-05-20 11:54:55.318 Session with id b83ce88a-4a02-41e3-a9d5-be290f8ee713 is already connected! Connecting to a new session.\n"
          ]
        }
      ],
      "source": [
        "!streamlit run app.py & npx localtunnel --port 8501"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SMuaNyrkYKQb"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}