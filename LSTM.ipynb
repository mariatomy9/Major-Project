{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mariatomy9/Major-Project/blob/hisana/LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dvn7Zf_LEobH",
        "outputId": "3f9cc99e-c2e6-4561-91d9-6b43344950d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: mne in /usr/local/lib/python3.9/dist-packages (1.3.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from mne) (4.65.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from mne) (23.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.9/dist-packages (from mne) (3.7.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from mne) (3.1.2)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.9/dist-packages (from mne) (1.22.4)\n",
            "Requirement already satisfied: pooch>=1.5 in /usr/local/lib/python3.9/dist-packages (from mne) (1.7.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.9/dist-packages (from mne) (4.4.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.9/dist-packages (from mne) (1.10.1)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.9/dist-packages (from pooch>=1.5->mne) (3.1.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.9/dist-packages (from pooch>=1.5->mne) (2.27.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->mne) (2.1.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mne) (1.4.4)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mne) (4.39.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mne) (2.8.2)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mne) (5.12.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mne) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mne) (0.11.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mne) (8.4.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mne) (1.0.7)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from importlib-resources>=3.2.0->matplotlib->mne) (3.15.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.7->matplotlib->mne) (1.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2.0.12)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: wfdb in /usr/local/lib/python3.9/dist-packages (4.1.0)\n",
            "Requirement already satisfied: pyEDFlib in /usr/local/lib/python3.9/dist-packages (0.1.30)\n",
            "Requirement already satisfied: PyWavelets in /usr/local/lib/python3.9/dist-packages (1.4.1)\n",
            "Requirement already satisfied: eeglib in /usr/local/lib/python3.9/dist-packages (0.4.1)\n",
            "Requirement already satisfied: pyeeg in /usr/local/lib/python3.9/dist-packages (0.0.2)\n",
            "Requirement already satisfied: matplotlib<4.0.0,>=3.2.2 in /usr/local/lib/python3.9/dist-packages (from wfdb) (3.7.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.10.1 in /usr/local/lib/python3.9/dist-packages (from wfdb) (1.22.4)\n",
            "Requirement already satisfied: SoundFile<0.12.0,>=0.10.0 in /usr/local/lib/python3.9/dist-packages (from wfdb) (0.11.0)\n",
            "Requirement already satisfied: pandas<2.0.0,>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from wfdb) (1.4.4)\n",
            "Requirement already satisfied: scipy<2.0.0,>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from wfdb) (1.10.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from wfdb) (2.27.1)\n",
            "Requirement already satisfied: progressbar2 in /usr/local/lib/python3.9/dist-packages (from eeglib) (3.38.0)\n",
            "Requirement already satisfied: fastdtw in /usr/local/lib/python3.9/dist-packages (from eeglib) (0.3.4)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.9/dist-packages (from eeglib) (0.0.post1)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.9/dist-packages (from eeglib) (0.56.4)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.9/dist-packages (from pyeeg) (1.5.1)\n",
            "Requirement already satisfied: websocket in /usr/local/lib/python3.9/dist-packages (from pyeeg) (0.2.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib<4.0.0,>=3.2.2->wfdb) (23.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib<4.0.0,>=3.2.2->wfdb) (3.0.9)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib<4.0.0,>=3.2.2->wfdb) (4.39.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib<4.0.0,>=3.2.2->wfdb) (1.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib<4.0.0,>=3.2.2->wfdb) (0.11.0)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib<4.0.0,>=3.2.2->wfdb) (5.12.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib<4.0.0,>=3.2.2->wfdb) (1.4.4)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib<4.0.0,>=3.2.2->wfdb) (8.4.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib<4.0.0,>=3.2.2->wfdb) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas<2.0.0,>=1.0.0->wfdb) (2022.7.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.8.1->wfdb) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.8.1->wfdb) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.8.1->wfdb) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.8.1->wfdb) (2.0.12)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.9/dist-packages (from SoundFile<0.12.0,>=0.10.0->wfdb) (1.15.1)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.9/dist-packages (from numba->eeglib) (0.39.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from numba->eeglib) (63.4.3)\n",
            "Requirement already satisfied: python-utils>=2.3.0 in /usr/local/lib/python3.9/dist-packages (from progressbar2->eeglib) (3.5.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.9/dist-packages (from progressbar2->eeglib) (1.15.0)\n",
            "Requirement already satisfied: greenlet in /usr/local/lib/python3.9/dist-packages (from websocket->pyeeg) (2.0.2)\n",
            "Requirement already satisfied: gevent in /usr/local/lib/python3.9/dist-packages (from websocket->pyeeg) (22.10.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.9/dist-packages (from cffi>=1.0->SoundFile<0.12.0,>=0.10.0->wfdb) (2.21)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from importlib-resources>=3.2.0->matplotlib<4.0.0,>=3.2.2->wfdb) (3.15.0)\n",
            "Requirement already satisfied: zope.interface in /usr/local/lib/python3.9/dist-packages (from gevent->websocket->pyeeg) (6.0)\n",
            "Requirement already satisfied: zope.event in /usr/local/lib/python3.9/dist-packages (from gevent->websocket->pyeeg) (4.6)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: wfdb in /usr/local/lib/python3.9/dist-packages (4.1.0)\n",
            "Requirement already satisfied: matplotlib<4.0.0,>=3.2.2 in /usr/local/lib/python3.9/dist-packages (from wfdb) (3.7.1)\n",
            "Requirement already satisfied: SoundFile<0.12.0,>=0.10.0 in /usr/local/lib/python3.9/dist-packages (from wfdb) (0.11.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.10.1 in /usr/local/lib/python3.9/dist-packages (from wfdb) (1.22.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from wfdb) (2.27.1)\n",
            "Requirement already satisfied: pandas<2.0.0,>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from wfdb) (1.4.4)\n",
            "Requirement already satisfied: scipy<2.0.0,>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from wfdb) (1.10.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib<4.0.0,>=3.2.2->wfdb) (1.4.4)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib<4.0.0,>=3.2.2->wfdb) (4.39.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib<4.0.0,>=3.2.2->wfdb) (0.11.0)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib<4.0.0,>=3.2.2->wfdb) (5.12.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib<4.0.0,>=3.2.2->wfdb) (1.0.7)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib<4.0.0,>=3.2.2->wfdb) (8.4.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib<4.0.0,>=3.2.2->wfdb) (2.8.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib<4.0.0,>=3.2.2->wfdb) (23.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib<4.0.0,>=3.2.2->wfdb) (3.0.9)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas<2.0.0,>=1.0.0->wfdb) (2022.7.1)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.8.1->wfdb) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.8.1->wfdb) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.8.1->wfdb) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.8.1->wfdb) (3.4)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.9/dist-packages (from SoundFile<0.12.0,>=0.10.0->wfdb) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.9/dist-packages (from cffi>=1.0->SoundFile<0.12.0,>=0.10.0->wfdb) (2.21)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from importlib-resources>=3.2.0->matplotlib<4.0.0,>=3.2.2->wfdb) (3.15.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.7->matplotlib<4.0.0,>=3.2.2->wfdb) (1.15.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyedflib in /usr/local/lib/python3.9/dist-packages (0.1.30)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.9/dist-packages (from pyedflib) (1.22.4)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: PyWavelets in /usr/local/lib/python3.9/dist-packages (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.9/dist-packages (from PyWavelets) (1.22.4)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: eeglib in /usr/local/lib/python3.9/dist-packages (0.4.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from eeglib) (1.4.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from eeglib) (1.22.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from eeglib) (1.10.1)\n",
            "Requirement already satisfied: pyedflib in /usr/local/lib/python3.9/dist-packages (from eeglib) (0.1.30)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.9/dist-packages (from eeglib) (0.0.post1)\n",
            "Requirement already satisfied: fastdtw in /usr/local/lib/python3.9/dist-packages (from eeglib) (0.3.4)\n",
            "Requirement already satisfied: progressbar2 in /usr/local/lib/python3.9/dist-packages (from eeglib) (3.38.0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.9/dist-packages (from eeglib) (0.56.4)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.9/dist-packages (from numba->eeglib) (0.39.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from numba->eeglib) (63.4.3)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->eeglib) (2022.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas->eeglib) (2.8.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.9/dist-packages (from progressbar2->eeglib) (1.15.0)\n",
            "Requirement already satisfied: python-utils>=2.3.0 in /usr/local/lib/python3.9/dist-packages (from progressbar2->eeglib) (3.5.2)\n",
            "/content/drive/MyDrive/Colab Notebooks/edfs/chb01_26.edf\n",
            "/content/drive/MyDrive/Colab Notebooks/edfs/chb01_03.edf\n",
            "/content/drive/MyDrive/Colab Notebooks/edfs/chb02_16+.edf\n",
            "/content/drive/MyDrive/Colab Notebooks/edfs/chb02_19.edf\n",
            "/content/drive/MyDrive/Colab Notebooks/edfs/chb03_04.edf\n",
            "/content/drive/MyDrive/Colab Notebooks/edfs/chb03_34.edf\n",
            "/content/drive/MyDrive/Colab Notebooks/edfs/chb03_35.edf\n",
            "/content/drive/MyDrive/Colab Notebooks/edfs/chb04_05.edf\n",
            "/content/drive/MyDrive/Colab Notebooks/edfs/chb04_08.edf\n",
            "/content/drive/MyDrive/Colab Notebooks/edfs/chb05_16.edf\n",
            "/content/drive/MyDrive/Colab Notebooks/edfs/chb05_17.edf\n",
            "/content/drive/MyDrive/Colab Notebooks/edfs/chb05_22.edf\n",
            "/content/drive/MyDrive/Colab Notebooks/edfs/chb06_09.edf\n",
            "/content/drive/MyDrive/Colab Notebooks/edfs/chb06_10.edf\n",
            "/content/drive/MyDrive/Colab Notebooks/edfs/chb06_18.edf\n",
            "/content/drive/MyDrive/Colab Notebooks/edfs/chb06_24.edf\n",
            "/content/drive/MyDrive/Colab Notebooks/edfs/chb07_12.edf\n",
            "/content/drive/MyDrive/Colab Notebooks/edfs/chb07_13.edf\n",
            "/content/drive/MyDrive/Colab Notebooks/edfs/chb07_18.edf\n",
            "/content/drive/MyDrive/Colab Notebooks/edfs/chb08_02.edf\n",
            "/content/drive/MyDrive/Colab Notebooks/edfs/chb08_05.edf\n",
            "/content/drive/MyDrive/Colab Notebooks/edfs/chb08_11.edf\n",
            "/content/drive/MyDrive/Colab Notebooks/edfs/chb08_13.edf\n",
            "/content/drive/MyDrive/Colab Notebooks/edfs/chb08_21.edf\n",
            "/content/drive/MyDrive/Colab Notebooks/edfs/chb09_06.edf\n",
            "/content/drive/MyDrive/Colab Notebooks/edfs/chb09_19.edf\n",
            "/content/drive/MyDrive/Colab Notebooks/edfs/chb10_12.edf\n",
            "/content/drive/MyDrive/Colab Notebooks/edfs/chb10_20.edf\n",
            "/content/drive/MyDrive/Colab Notebooks/edfs/chb10_27.edf\n",
            "/content/drive/MyDrive/Colab Notebooks/edfs/chb10_30.edf\n",
            "/content/drive/MyDrive/Colab Notebooks/edfs/chb10_31.edf\n",
            "/content/drive/MyDrive/Colab Notebooks/edfs/chb10_38.edf\n",
            "/content/drive/MyDrive/Colab Notebooks/edfs/chb11_92.edf\n",
            "/content/drive/MyDrive/Colab Notebooks/edfs/chb13_19.edf\n",
            "/content/drive/MyDrive/Colab Notebooks/edfs/chb13_58.edf\n",
            "/content/drive/MyDrive/Colab Notebooks/edfs/chb13_59.edf\n",
            "/content/drive/MyDrive/Colab Notebooks/edfs/chb14_03.edf\n",
            "/content/drive/MyDrive/Colab Notebooks/edfs/chb14_06.edf\n",
            "/content/drive/MyDrive/Colab Notebooks/edfs/chb14_11.edf\n",
            "/content/drive/MyDrive/Colab Notebooks/edfs/chb14_17.edf\n",
            "/content/drive/MyDrive/Colab Notebooks/edfs/chb14_27.edf\n",
            "/content/drive/MyDrive/Colab Notebooks/edfs/chb15_17.edf\n",
            "/content/drive/MyDrive/Colab Notebooks/edfs/chb15_46.edf\n",
            "/content/drive/MyDrive/Colab Notebooks/edfs/chb16_10.edf\n",
            "/content/drive/MyDrive/Colab Notebooks/edfs/chb16_14.edf\n",
            "/content/drive/MyDrive/Colab Notebooks/edfs/chb17a_03.edf\n",
            "/content/drive/MyDrive/Colab Notebooks/edfs/chb17a_04.edf\n",
            "/content/drive/MyDrive/Colab Notebooks/edfs/chb17b_63.edf\n",
            "/content/drive/MyDrive/Colab Notebooks/edfs/chb18_29.edf\n",
            "/content/drive/MyDrive/Colab Notebooks/edfs/chb18_31.edf\n",
            "/content/drive/MyDrive/Colab Notebooks/edfs/chb18_32.edf\n",
            "/content/drive/MyDrive/Colab Notebooks/edfs/chb18_35.edf\n",
            "/content/drive/MyDrive/Colab Notebooks/edfs/chb19_29.edf\n",
            "/content/drive/MyDrive/Colab Notebooks/edfs/chb19_30.edf\n",
            "/content/drive/MyDrive/Colab Notebooks/edfs/chb20_14.edf\n",
            "/content/drive/MyDrive/Colab Notebooks/edfs/chb20_16.edf\n",
            "/content/drive/MyDrive/Colab Notebooks/edfs/chb21_20.edf\n",
            "/content/drive/MyDrive/Colab Notebooks/edfs/chb21_21.edf\n",
            "/content/drive/MyDrive/Colab Notebooks/edfs/chb21_22.edf\n",
            "/content/drive/MyDrive/Colab Notebooks/edfs/chb22_20.edf\n",
            "/content/drive/MyDrive/Colab Notebooks/edfs/chb22_25.edf\n",
            "/content/drive/MyDrive/Colab Notebooks/edfs/chb23_06.edf\n",
            "/content/drive/MyDrive/Colab Notebooks/edfs/chb24_11.edf\n",
            "/content/drive/MyDrive/Colab Notebooks/edfs/chb24_13.edf\n",
            "/content/drive/MyDrive/Colab Notebooks/edfs/chb24_14.edf\n",
            "/content/drive/MyDrive/Colab Notebooks/edfs/chb24_15.edf\n",
            "/content/drive/MyDrive/Colab Notebooks/edfs/chb24_17.edf\n",
            "/content/drive/MyDrive/Colab Notebooks/edfs/chb24_21.edf\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from random import sample\n",
        "from datetime import datetime\n",
        "import collections\n",
        "\n",
        "!pip install -q tensorflow_addons\n",
        "import tensorflow_addons as tfa\n",
        "\n",
        "!pip install mne\n",
        "\n",
        "import mne\n",
        "\n",
        "!pip install wfdb pyEDFlib PyWavelets eeglib wfdb pyeeg\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "!pip install wfdb\n",
        "!pip install pyedflib \n",
        "!pip install PyWavelets\n",
        "\n",
        "\n",
        "import wfdb\n",
        "import pyedflib\n",
        "import pywt \n",
        "\n",
        "!pip install eeglib\n",
        "\n",
        "\n",
        "from mne import Epochs, create_info, events_from_annotations\n",
        "from mne.io import concatenate_raws, read_raw_edf\n",
        "from mne.decoding import CSP\n",
        "from mne.time_frequency import AverageTFR\n",
        "from mne.decoding import Vectorizer\n",
        "from mne.io import concatenate_raws, read_raw_edf\n",
        "from mne import Epochs, create_info, events_from_annotations, pick_events, pick_types\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.model_selection import cross_val_score, train_test_split, GridSearchCV, StratifiedKFold\n",
        "from sklearn.metrics import classification_report, accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/content/drive/MyDrive/Colab Notebooks/edfs'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargamos la lista de todos los seizures y sus tiempos en cada fichero\n",
        "df_seizures = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/seizures summary.csv',delimiter=';', encoding='utf8')"
      ],
      "metadata": {
        "id": "4fwYSsYLugK5"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_seizures"
      ],
      "metadata": {
        "id": "uFkqTMfNwVwd",
        "outputId": "6f9cf315-d67b-4c66-9b05-71970c465edc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 557
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   paciente  num recording         ruta+archivo nombre archivo        npy  \\\n",
              "0     chb01              3   chb01/chb01_03.edf   chb01_03.edf   chb01_03   \n",
              "1     chb01             26   chb01/chb01_26.edf   chb01_26.edf   chb01_26   \n",
              "2     chb02             16  chb02/chb02_16+.edf  chb02_16+.edf  chb02_16+   \n",
              "3     chb02             19   chb02/chb02_19.edf   chb02_19.edf   chb02_19   \n",
              "4     chb03              4   chb03/chb03_04.edf   chb03_04.edf   chb03_04   \n",
              "..      ...            ...                  ...            ...        ...   \n",
              "62    chb24             13   chb24/chb24_13.edf   chb24_13.edf   chb24_13   \n",
              "63    chb24             14   chb24/chb24_14.edf   chb24_14.edf   chb24_14   \n",
              "64    chb24             15   chb24/chb24_15.edf   chb24_15.edf   chb24_15   \n",
              "65    chb24             17   chb24/chb24_17.edf   chb24_17.edf   chb24_17   \n",
              "66    chb24             21   chb24/chb24_21.edf   chb24_21.edf   chb24_21   \n",
              "\n",
              "    inicio seizure segundos  fin seizure segundos  tiempo inicial seizure  \\\n",
              "0                      2996                  3036                  766976   \n",
              "1                      1862                  1963                  476672   \n",
              "2                      2972                  3053                  760832   \n",
              "3                      3369                  3378                  862464   \n",
              "4                      2162                  2214                  553472   \n",
              "..                      ...                   ...                     ...   \n",
              "62                     3288                  3304                  841728   \n",
              "63                     1939                  1966                  496384   \n",
              "64                     3552                  3569                  909312   \n",
              "65                     3515                  3581                  899840   \n",
              "66                     2804                  2872                  717824   \n",
              "\n",
              "    tiempo final seizure  10 minutos antes de seizure  interictal inicio  \\\n",
              "0                 777216                       613376             153598   \n",
              "1                 502528                       323072             153598   \n",
              "2                 781568                       607232             153598   \n",
              "3                 864768                       708864             153598   \n",
              "4                 566784                       399872             153598   \n",
              "..                   ...                          ...                ...   \n",
              "62                845824                       688128             153598   \n",
              "63                503296                       342784             153598   \n",
              "64                913664                       755712             153598   \n",
              "65                916736                       746240             153598   \n",
              "66                735232                       564224             153598   \n",
              "\n",
              "    interictal fin  preictal inicio  preictal fin  ictal inicio  ictal fin  \\\n",
              "0           613374           613375        766975        766976     777216   \n",
              "1           323070           323071        476671        476672     502528   \n",
              "2           607230           607231        760831        760832     781568   \n",
              "3           708862           708863        862463        862464     864768   \n",
              "4           399870           399871        553471        553472     566784   \n",
              "..             ...              ...           ...           ...        ...   \n",
              "62          688126           688127        841727        841728     845824   \n",
              "63          342782           342783        496383        496384     503296   \n",
              "64          755710           755711        909311        909312     913664   \n",
              "65          746238           746239        899839        899840     916736   \n",
              "66          564222           564223        717823        717824     735232   \n",
              "\n",
              "    duracion interictal (m)  duracion preictal (m)  duracion ictal (m)  \n",
              "0                     29.93                     10                0.67  \n",
              "1                     11.03                     10                1.68  \n",
              "2                     29.53                     10                1.35  \n",
              "3                     36.15                     10                0.15  \n",
              "4                     16.03                     10                0.87  \n",
              "..                      ...                    ...                 ...  \n",
              "62                    34.80                     10                0.27  \n",
              "63                    12.32                     10                0.45  \n",
              "64                    39.20                     10                0.28  \n",
              "65                    38.58                     10                1.10  \n",
              "66                    26.73                     10                1.13  \n",
              "\n",
              "[67 rows x 19 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-14a4e3bd-9ab8-4093-85fe-2edc05898f5e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>paciente</th>\n",
              "      <th>num recording</th>\n",
              "      <th>ruta+archivo</th>\n",
              "      <th>nombre archivo</th>\n",
              "      <th>npy</th>\n",
              "      <th>inicio seizure segundos</th>\n",
              "      <th>fin seizure segundos</th>\n",
              "      <th>tiempo inicial seizure</th>\n",
              "      <th>tiempo final seizure</th>\n",
              "      <th>10 minutos antes de seizure</th>\n",
              "      <th>interictal inicio</th>\n",
              "      <th>interictal fin</th>\n",
              "      <th>preictal inicio</th>\n",
              "      <th>preictal fin</th>\n",
              "      <th>ictal inicio</th>\n",
              "      <th>ictal fin</th>\n",
              "      <th>duracion interictal (m)</th>\n",
              "      <th>duracion preictal (m)</th>\n",
              "      <th>duracion ictal (m)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>chb01</td>\n",
              "      <td>3</td>\n",
              "      <td>chb01/chb01_03.edf</td>\n",
              "      <td>chb01_03.edf</td>\n",
              "      <td>chb01_03</td>\n",
              "      <td>2996</td>\n",
              "      <td>3036</td>\n",
              "      <td>766976</td>\n",
              "      <td>777216</td>\n",
              "      <td>613376</td>\n",
              "      <td>153598</td>\n",
              "      <td>613374</td>\n",
              "      <td>613375</td>\n",
              "      <td>766975</td>\n",
              "      <td>766976</td>\n",
              "      <td>777216</td>\n",
              "      <td>29.93</td>\n",
              "      <td>10</td>\n",
              "      <td>0.67</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>chb01</td>\n",
              "      <td>26</td>\n",
              "      <td>chb01/chb01_26.edf</td>\n",
              "      <td>chb01_26.edf</td>\n",
              "      <td>chb01_26</td>\n",
              "      <td>1862</td>\n",
              "      <td>1963</td>\n",
              "      <td>476672</td>\n",
              "      <td>502528</td>\n",
              "      <td>323072</td>\n",
              "      <td>153598</td>\n",
              "      <td>323070</td>\n",
              "      <td>323071</td>\n",
              "      <td>476671</td>\n",
              "      <td>476672</td>\n",
              "      <td>502528</td>\n",
              "      <td>11.03</td>\n",
              "      <td>10</td>\n",
              "      <td>1.68</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>chb02</td>\n",
              "      <td>16</td>\n",
              "      <td>chb02/chb02_16+.edf</td>\n",
              "      <td>chb02_16+.edf</td>\n",
              "      <td>chb02_16+</td>\n",
              "      <td>2972</td>\n",
              "      <td>3053</td>\n",
              "      <td>760832</td>\n",
              "      <td>781568</td>\n",
              "      <td>607232</td>\n",
              "      <td>153598</td>\n",
              "      <td>607230</td>\n",
              "      <td>607231</td>\n",
              "      <td>760831</td>\n",
              "      <td>760832</td>\n",
              "      <td>781568</td>\n",
              "      <td>29.53</td>\n",
              "      <td>10</td>\n",
              "      <td>1.35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>chb02</td>\n",
              "      <td>19</td>\n",
              "      <td>chb02/chb02_19.edf</td>\n",
              "      <td>chb02_19.edf</td>\n",
              "      <td>chb02_19</td>\n",
              "      <td>3369</td>\n",
              "      <td>3378</td>\n",
              "      <td>862464</td>\n",
              "      <td>864768</td>\n",
              "      <td>708864</td>\n",
              "      <td>153598</td>\n",
              "      <td>708862</td>\n",
              "      <td>708863</td>\n",
              "      <td>862463</td>\n",
              "      <td>862464</td>\n",
              "      <td>864768</td>\n",
              "      <td>36.15</td>\n",
              "      <td>10</td>\n",
              "      <td>0.15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>chb03</td>\n",
              "      <td>4</td>\n",
              "      <td>chb03/chb03_04.edf</td>\n",
              "      <td>chb03_04.edf</td>\n",
              "      <td>chb03_04</td>\n",
              "      <td>2162</td>\n",
              "      <td>2214</td>\n",
              "      <td>553472</td>\n",
              "      <td>566784</td>\n",
              "      <td>399872</td>\n",
              "      <td>153598</td>\n",
              "      <td>399870</td>\n",
              "      <td>399871</td>\n",
              "      <td>553471</td>\n",
              "      <td>553472</td>\n",
              "      <td>566784</td>\n",
              "      <td>16.03</td>\n",
              "      <td>10</td>\n",
              "      <td>0.87</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62</th>\n",
              "      <td>chb24</td>\n",
              "      <td>13</td>\n",
              "      <td>chb24/chb24_13.edf</td>\n",
              "      <td>chb24_13.edf</td>\n",
              "      <td>chb24_13</td>\n",
              "      <td>3288</td>\n",
              "      <td>3304</td>\n",
              "      <td>841728</td>\n",
              "      <td>845824</td>\n",
              "      <td>688128</td>\n",
              "      <td>153598</td>\n",
              "      <td>688126</td>\n",
              "      <td>688127</td>\n",
              "      <td>841727</td>\n",
              "      <td>841728</td>\n",
              "      <td>845824</td>\n",
              "      <td>34.80</td>\n",
              "      <td>10</td>\n",
              "      <td>0.27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63</th>\n",
              "      <td>chb24</td>\n",
              "      <td>14</td>\n",
              "      <td>chb24/chb24_14.edf</td>\n",
              "      <td>chb24_14.edf</td>\n",
              "      <td>chb24_14</td>\n",
              "      <td>1939</td>\n",
              "      <td>1966</td>\n",
              "      <td>496384</td>\n",
              "      <td>503296</td>\n",
              "      <td>342784</td>\n",
              "      <td>153598</td>\n",
              "      <td>342782</td>\n",
              "      <td>342783</td>\n",
              "      <td>496383</td>\n",
              "      <td>496384</td>\n",
              "      <td>503296</td>\n",
              "      <td>12.32</td>\n",
              "      <td>10</td>\n",
              "      <td>0.45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64</th>\n",
              "      <td>chb24</td>\n",
              "      <td>15</td>\n",
              "      <td>chb24/chb24_15.edf</td>\n",
              "      <td>chb24_15.edf</td>\n",
              "      <td>chb24_15</td>\n",
              "      <td>3552</td>\n",
              "      <td>3569</td>\n",
              "      <td>909312</td>\n",
              "      <td>913664</td>\n",
              "      <td>755712</td>\n",
              "      <td>153598</td>\n",
              "      <td>755710</td>\n",
              "      <td>755711</td>\n",
              "      <td>909311</td>\n",
              "      <td>909312</td>\n",
              "      <td>913664</td>\n",
              "      <td>39.20</td>\n",
              "      <td>10</td>\n",
              "      <td>0.28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65</th>\n",
              "      <td>chb24</td>\n",
              "      <td>17</td>\n",
              "      <td>chb24/chb24_17.edf</td>\n",
              "      <td>chb24_17.edf</td>\n",
              "      <td>chb24_17</td>\n",
              "      <td>3515</td>\n",
              "      <td>3581</td>\n",
              "      <td>899840</td>\n",
              "      <td>916736</td>\n",
              "      <td>746240</td>\n",
              "      <td>153598</td>\n",
              "      <td>746238</td>\n",
              "      <td>746239</td>\n",
              "      <td>899839</td>\n",
              "      <td>899840</td>\n",
              "      <td>916736</td>\n",
              "      <td>38.58</td>\n",
              "      <td>10</td>\n",
              "      <td>1.10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66</th>\n",
              "      <td>chb24</td>\n",
              "      <td>21</td>\n",
              "      <td>chb24/chb24_21.edf</td>\n",
              "      <td>chb24_21.edf</td>\n",
              "      <td>chb24_21</td>\n",
              "      <td>2804</td>\n",
              "      <td>2872</td>\n",
              "      <td>717824</td>\n",
              "      <td>735232</td>\n",
              "      <td>564224</td>\n",
              "      <td>153598</td>\n",
              "      <td>564222</td>\n",
              "      <td>564223</td>\n",
              "      <td>717823</td>\n",
              "      <td>717824</td>\n",
              "      <td>735232</td>\n",
              "      <td>26.73</td>\n",
              "      <td>10</td>\n",
              "      <td>1.13</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>67 rows × 19 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-14a4e3bd-9ab8-4093-85fe-2edc05898f5e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-14a4e3bd-9ab8-4093-85fe-2edc05898f5e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-14a4e3bd-9ab8-4093-85fe-2edc05898f5e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "XeHFBU5DMShP"
      },
      "outputs": [],
      "source": [
        "from mne.io import concatenate_raws, read_raw_edf\n",
        "from mne import Epochs, create_info, events_from_annotations, pick_events, pick_types\n",
        "\n",
        "lista_erroneos = ['chb10_31.edf', 'chb04_05.edf','chb04_08.edf', 'chb09_19.edf', 'chb09_06.edf', 'chb06_18.edf','chb10_20.edf',\n",
        "                  'chb10_38.edf', 'chb10_12.edf', 'chb23_06.edf', 'chb06_10.edf', 'chb06_24.edf', 'chb06_09.edf', 'chb07_12.edf', \n",
        "                  'chb10_27.edf']\n",
        "\n",
        "df_seizures = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/seizures summary.csv',delimiter=';', encoding='utf8')\n",
        "\n",
        "df_seizures = df_seizures[~df_seizures['nombre archivo'].isin(lista_erroneos)]\n",
        "\n",
        "def lee_raw(paciente):\n",
        "    \n",
        "    #elegidos=[]\n",
        "\n",
        "    #for i in np.random.choice(df_seizures['paciente'].unique(), 1):\n",
        "    #for i in paciente:\n",
        "        #np.random.choice(df_seizures['paciente'].unique(), 1):\n",
        "        #elegidos.append(np.random.choice(df_seizures[df_seizures['paciente'] == i]['nombre archivo']))\n",
        "    #elegidos.append(np.random.choice(df_seizures[df_seizures['paciente'] == paciente]['nombre archivo'],1) )\n",
        "    \n",
        "    #elegidos.append(df_seizures[df_seizures['paciente'] == paciente]['nombre archivo'].sample().to_list()[0])\n",
        "    \n",
        "    elegido = df_seizures[df_seizures['paciente'] == paciente]['nombre archivo'].sample().to_list()[0]\n",
        "\n",
        "    # Path with the recordings\n",
        "    myPath = '/content/drive/MyDrive/Colab Notebooks/edfs'\n",
        "    # Ficheros totales (All patients)\n",
        "    data = os.listdir(myPath)\n",
        "    \n",
        "    #epochs_all llevará todos los epochs de todos los pacientes que seleccionemos.\n",
        "    epochs_all = np.empty(shape=())  # Empty array with size =  1\n",
        "    data_all = np.empty(shape=()) # Empty array with size =  1\n",
        "    epochs_all_10 = np.empty(shape=())  # Empty array with size =  1\n",
        "\n",
        "    count = 0\n",
        "    \n",
        "    #print(\"Elegidos : {}\".format(elegidos))\n",
        "    #for i in elegidos:\n",
        "        #print(\"type de i:{} and {}\".format(type(i), i))\n",
        "        #dataPath = os.path.join(myPath, data[i])\n",
        "    \n",
        "    dataPath = os.path.join(myPath, str(elegido))\n",
        "        \n",
        "    # We read our EDF recording and build a generic 'mapping' of channels that\n",
        "    # we will remove since they are wrong or reference channels.\n",
        "    mapping = {'EOG horizontal': 'eog', 'Resp oro-nasal': 'misc',\n",
        "               'EMG submental': 'misc', 'Temp rectal': 'misc', \n",
        "               'Event marker': 'misc', '-': 'misc', '.': 'misc', 'T8-P8':'T8-P8',\n",
        "               'FC1-Ref':'FC1-Ref', 'FC2-Ref':'FC2-Ref', 'FC5-Ref':'FC5-Ref',\n",
        "               'FC6-Ref':'FC6-Ref', 'CP1-Ref':'CP1-Ref','CP2-Ref':'CP2-Ref',\n",
        "               'CP5-Ref':'CP5-Ref', 'CP6-Ref':'CP6-Ref', 'PZ-OZ':'PZ-OZ'}\n",
        "    \n",
        "        # We will specifically exclude the channel with issues (T8-P8) and the weird channels (. and -)\n",
        "    excluded_channels = mapping.keys()\n",
        "        \n",
        "    if str(elegido) in df_seizures['nombre archivo'].to_list():\n",
        "        \n",
        "        print(\"Leyendo fichero...:{}\".format(elegido))\n",
        "        print(\"Desde :{}\".format(myPath+elegido))\n",
        "        count +=1\n",
        "        raw = mne.io.read_raw_edf(myPath+elegido, exclude=excluded_channels, preload=True, stim_channel='auto', verbose=None)\n",
        "     \n",
        "        raw = raw.resample(sfreq=127)\n",
        "\n",
        "        #raw = mne.io.read_raw_edf(path, exclude=['-', 'T8-P8', '.'], verbose=False, preload=True)\n",
        "\n",
        "        # Rename EEG channels\n",
        "        ch_names = {i: i.replace('EEG ', '') for i in raw.ch_names if 'EEG' in i}\n",
        "        mne.rename_channels(raw.info, ch_names)\n",
        "        \n",
        "        \n",
        "        \n",
        "        # We then apply notch filter around 60 Hz. (USA) or 50Hz (Europe) This is recommended by some papers to eliminate noise from electrodes (power line).\n",
        "        raw = raw.notch_filter(freqs=[59.1, 60.9])\n",
        "\n",
        "        # We then apply the alpha and beta filters that go from 7 to 26/28 Hz (FIRWIN type, default for MNE/Scipy)\n",
        "        raw = raw.filter(l_freq=8.0, h_freq=29.0)\n",
        "\n",
        "        # Now we mark the starts and ends of the seizures to obtain the class (Inter, Preictal, Ictal) for each second.\n",
        "        seizure_init = float(df_seizures[df_seizures['nombre archivo']==elegido]['inicio seizure segundos'].to_list()[0])\n",
        "        # print(\"seiz init\", seizure_init)\n",
        "        seizure_end = float(df_seizures[df_seizures['nombre archivo']==elegido]['fin seizure segundos'].to_list()[0])\n",
        "        duration_seiz = float(seizure_end-seizure_init)\n",
        "    \n",
        "        preictal_init = float(seizure_init - 10*60)  # 10 minutos (se puede aumentar)\n",
        "        preictal_duration = float(seizure_init - preictal_init)\n",
        "        print(\"seiz_init, preictal_duration y seizure_end\", seizure_init, preictal_duration, seizure_end)\n",
        "\n",
        "        normal_antes_pre_dur = float(preictal_init)\n",
        "        normal_despues_seiz_dur = float(3600 - seizure_end)\n",
        "\n",
        "        this_file_annots = mne.Annotations(onset=[0, preictal_init, seizure_init, seizure_end ],  # in seconds\n",
        "            duration=[normal_antes_pre_dur, preictal_duration, duration_seiz, normal_despues_seiz_dur],  # in seconds, too\n",
        "            description=['Inter','Preictal','Ictal', 'Inter'],\n",
        "            ch_names = None)\n",
        "        \n",
        "        raw.set_annotations(this_file_annots)\n",
        "        \n",
        "                \n",
        "        # Recogemos los eventos de las anotaciones (para construir los futuros epochs a partir de eventos)\n",
        "        # También podríamos usar duration=2.5 y overlap=0.5\n",
        "        events, events_ids = mne.events_from_annotations(raw, event_id={'Preictal':0, 'Ictal':2, 'Inter':1}, \n",
        "                                                         chunk_duration=1, use_rounding=True )\n",
        "        \n",
        "        # Finally we crop the first minute to reduce noise (1 m. until patient settles)\n",
        "        crop_file_mins = 1\n",
        "        if crop_file_mins > 0:  # Cut start of file\n",
        "            # Crop raw\n",
        "            tmin_crop = crop_file_mins * 60\n",
        "            #tmax = crop_file_mins * 60\n",
        "            raw.crop(tmin=tmin_crop)\n",
        "        \n",
        "        # Save subject and recording information in raw.info\n",
        "        # Guardamos la info del fichero: paciente/fichero.\n",
        "        basename = elegido\n",
        "        #print(int(basename[3:5]))\n",
        "\n",
        "        subj_nb, rec_nb = str(basename[3:6]), str(basename[7:8])\n",
        "        # print(\"Los integers\", subj_nb, rec_nb)\n",
        "\n",
        "        raw.info['patient_info'] = {'id': subj_nb, 'fichero_id': rec_nb}\n",
        "\n",
        "        print('Patient_info info: {}'.format(raw.info['patient_info'])+'\\n')\n",
        "\n",
        "        if count == 1:\n",
        "\n",
        "            raw_final = raw.get_data()\n",
        "\n",
        "        else:\n",
        "\n",
        "            raw_final = np.append(raw_final, raw.get_data(), axis=1)\n",
        "\n",
        "        #mne.concatenate_epochs(epochs_list, add_offset=True, *, on_mismatch='raise', verbose=None)\n",
        "\n",
        "        picks = pick_types(raw.info, meg=False, eeg=True, stim=False, eog=False, exclude='bads')\n",
        "\n",
        "        # Jugando con tmin y tmax podemos obtener epochs de mas o menos duracion y/o solapamiento \n",
        "        epochs_all_tmp = mne.Epochs(raw, picks=picks, events=events, event_repeated = 'merge', \n",
        "                         event_id=events_ids, tmin=-0.0001, tmax=1.0, baseline =(None,None),\n",
        "                         preload=True)\n",
        "        \n",
        "        # Construimos epochs (con el objeto Raw epochs_all_tmp de cada fichero).\n",
        "        if data_all.size > 1:\n",
        "\n",
        "            #epochs_all = np.append(epochs_all, epochs_all_tmp.get_data(), axis=0)\n",
        "\n",
        "            epochs_PIN = epochs_all_tmp['Preictal', 'Ictal', 'Inter']\n",
        "            final_df = final_df.append(epochs_PIN.to_data_frame())\n",
        "\n",
        "            data_all_tmp = epochs_PIN.get_data()\n",
        "            print('size of tmp : {}'.format(data_all_tmp.shape) +'\\n')\n",
        "            data_all = np.append(data_all, data_all_tmp, axis=0)\n",
        "\n",
        "            #labels_data_tmp = epochs_all_tmp.events[:,-1]\n",
        "\n",
        "            labels_data_all = np.append(labels_data_all, epochs_PIN.events[:,-1], axis = 0)\n",
        "\n",
        "            #epochs_all_10 = np.append(epochs_all_10, epochs_all_tmp_10, axis=0)\n",
        "\n",
        "        else:\n",
        "            \n",
        "            epochs_all = mne.Epochs(raw, picks=picks, events=events, event_repeated = 'merge', \n",
        "                         event_id=events_ids, tmin=-0.0001, tmax=1.0, baseline =(None,None),\n",
        "                         preload=True)\n",
        "\n",
        "            epochs_PIN = epochs_all['Preictal', 'Ictal', 'Inter']\n",
        "                \n",
        "            # Para 'unificar' clases por tamanos. \n",
        "            # epochs_PIN.equalize_event_counts(list(events_ids.keys()))\n",
        "                \n",
        "            final_df = epochs_PIN.to_data_frame()\n",
        "\n",
        "            data_all = epochs_PIN.get_data()\n",
        "\n",
        "            #print('size of dataall :{}'.format(data_all.shape) + '\\n')\n",
        "            labels_data_all = epochs_PIN.events[:,-1]\n",
        "\n",
        "            #epochs_all_10 = epochs_all_tmp_10\n",
        "\n",
        "#    else:\n",
        "\n",
        "#        continue\n",
        "    final_df['cat'] = [1 if i == 'Preictal' else 2 if i == 'Ictal' else 0 for i in final_df['condition']]\n",
        "    \n",
        "    return final_df"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_cwt(DF, wavelet, ventana=10, solapamiento=0, fs = 128):\n",
        "    \n",
        "    fs = fs\n",
        "    final_df = DF\n",
        "    waveletname = pywt.ContinuousWavelet(wavelet)\n",
        "    escalas = pywt.scale2frequency(waveletname.name, np.arange(8,30.5,2)) / (1/fs)\n",
        "    print(\"Numero de escalas que vamos a probar : {}\".format(len(escalas)))\n",
        "    ventana = ventana\n",
        "    incremento = fs * ventana  # La ventana me da el incremento o 'avance' en cada iteracion\n",
        "    solapamiento = solapamiento * fs\n",
        "    \n",
        "    train_size = int(np.floor(final_df.shape[0]/(ventana*fs)))\n",
        "    \n",
        "    n_channels = len(final_df.columns) - 4\n",
        "    # Redondeamos para evitar el último epoch que desbordaría\n",
        "    tamano_resultado_train = int(round(train_size,0))\n",
        "    \n",
        "    # Matriz resultado en train (tamaño muestras, escalas, freq.samp, canales)\n",
        "    train_data_cwt = np.ndarray(shape=(tamano_resultado_train, len(escalas), fs, n_channels))\n",
        "    train_data_cwt_labels = np.ndarray(shape=(tamano_resultado_train, 1, n_channels))\n",
        "    \n",
        "    for ii in range(0,tamano_resultado_train):\n",
        "        if ii == int(np.floor(tamano_resultado_train/2)):\n",
        "            print(\"CWT en set training a la mitad...{}\".format(ii*incremento))\n",
        "    \n",
        "        for jj in range(0,n_channels):\n",
        "        \n",
        "            start = final_df['epoch'].min()\n",
        " \n",
        "            signal = final_df.iloc[ii*(incremento - solapamiento):(ii+1)*(incremento-solapamiento), jj+3:jj+4]\n",
        "    \n",
        "            # Calculamos la clase con el 'techo' del valor de la mediana de cada ventana\n",
        "            clase_intervalo = int(np.ceil(np.median(final_df.iloc[ii*(incremento- solapamiento) : (ii+1)*(incremento- solapamiento), -1])))\n",
        "  \n",
        "            train_data_cwt_labels[ii, : ,jj] = clase_intervalo\n",
        "        \n",
        "            coeff, freq = pywt.cwt(signal, escalas, waveletname, 1)\n",
        "        \n",
        "            coeff_approx = coeff[:,:fs]\n",
        "        \n",
        "            train_data_cwt[ii, :, :, jj] = abs(coeff_approx[:,:,-1])\n",
        "    \n",
        "    print(\"Final CWT decomp. \\n\") \n",
        "    \n",
        "    return train_data_cwt, train_data_cwt_labels"
      ],
      "metadata": {
        "id": "cDr6MxbXdst8"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fs = 128\n",
        "escalas = pywt.scale2frequency('cmor3-3', np.arange(8,30.5,2) / (1/fs))\n",
        "print(\"Numero de escalas que vamos a probar : {}\".format(len(escalas)))"
      ],
      "metadata": {
        "id": "CkvWkQ0pd0Sp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a505553-8e0f-4038-c293-6a97391b5d07"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Numero de escalas que vamos a probar : 12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Resultados individualizados\n",
        "\n",
        "segundos = [5]\n",
        "wavelets = ['morl', 'mexh']\n",
        "solapamientos = [0]\n",
        "resultados = dict()\n",
        "#for i in df_seizures['paciente'].unique():\n",
        "for i in np.random.choice(df_seizures['paciente'].unique(),8).tolist():\n",
        "    temp = lee_raw(i)\n",
        "    #lectura_edf = obtain_edf(i)\n",
        "    for j in segundos:\n",
        "        for k in wavelets:        \n",
        "            resultados.update({'paciente_'+i+'_'+str(j)+'_'+k: temp})\n",
        "            resultados.update({'paciente_'+i+'_'+str(j)+'_'+k: compute_cwt(temp, k, j, 0)})\n",
        "            #numpy.save(\"npy.npy\", data)\n",
        " "
      ],
      "metadata": {
        "id": "kgglHe8od-fp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 537
        },
        "outputId": "bb213334-fe08-40e9-b2d8-1b158e09e7f6"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Leyendo fichero...:chb22_25.edf\n",
            "Desde :/content/drive/MyDrive/Colab Notebooks/edfschb22_25.edf\n",
            "Extracting EDF parameters from /content/drive/MyDrive/Colab Notebooks/edfschb22_25.edf...\n",
            "EDF file detected\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-3806b437f59d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#for i in df_seizures['paciente'].unique():\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_seizures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'paciente'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlee_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0;31m#lectura_edf = obtain_edf(i)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msegundos\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-21-d8155f02c99d>\u001b[0m in \u001b[0;36mlee_raw\u001b[0;34m(paciente)\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Desde :{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmyPath\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0melegido\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mcount\u001b[0m \u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0mraw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmne\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_raw_edf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmyPath\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0melegido\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexcluded_channels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstim_channel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'auto'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mraw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mraw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msfreq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m127\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/mne/io/edf/edf.py\u001b[0m in \u001b[0;36mread_raw_edf\u001b[0;34m(input_fname, eog, misc, stim_channel, exclude, infer_types, include, preload, units, encoding, verbose)\u001b[0m\n\u001b[1;32m   1410\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mext\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'edf'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Only EDF files are supported, got {ext}.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1412\u001b[0;31m     return RawEDF(input_fname=input_fname, eog=eog, misc=misc,\n\u001b[0m\u001b[1;32m   1413\u001b[0m                   \u001b[0mstim_channel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstim_channel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexclude\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1414\u001b[0m                   \u001b[0minfer_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minfer_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpreload\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minclude\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-365>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_fname, eog, misc, stim_channel, exclude, infer_types, preload, include, units, encoding, verbose)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/mne/io/edf/edf.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_fname, eog, misc, stim_channel, exclude, infer_types, preload, include, units, encoding, verbose)\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Extracting EDF parameters from {}...'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0minput_fname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m         info, edf_info, orig_units = _get_info(input_fname, stim_channel, eog,\n\u001b[0m\u001b[1;32m    142\u001b[0m                                                \u001b[0mmisc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfer_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m                                                preload, include)\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/mne/io/edf/edf.py\u001b[0m in \u001b[0;36m_get_info\u001b[0;34m(fname, stim_channel, eog, misc, exclude, infer_types, preload, include)\u001b[0m\n\u001b[1;32m    428\u001b[0m     \u001b[0mmisc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmisc\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmisc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m     \u001b[0medf_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_units\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_header\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfer_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m     \u001b[0;31m# XXX: `tal_ch_names` to pass to `_check_stim_channel` should be computed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/mne/io/edf/edf.py\u001b[0m in \u001b[0;36m_read_header\u001b[0;34m(fname, exclude, infer_types, include)\u001b[0m\n\u001b[1;32m    414\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%s file detected'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mext\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'bdf'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'edf'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read_edf_header\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfer_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mext\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'gdf'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read_gdf_header\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/mne/io/edf/edf.py\u001b[0m in \u001b[0;36m_read_edf_header\u001b[0;34m(fname, exclude, infer_types, include)\u001b[0m\n\u001b[1;32m    636\u001b[0m     \u001b[0medf_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'events'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfid\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m         \u001b[0mfid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# version (unused here)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/Colab Notebooks/edfschb22_25.edf'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from keras.layers import Dense, Flatten, Dropout, LSTM\n",
        "from keras.layers import Conv2D, MaxPooling2D, Conv3D, MaxPooling3D\n",
        "from keras.models import Sequential\n",
        "from keras.callbacks import History\n",
        "#from keras.optimizers import SGD\n",
        "\n",
        "\n",
        "num_escalas = list(resultados.values())[0][0].shape[1]\n",
        "coeficientes = list(resultados.values())[0][0].shape[2]\n",
        "canales = list(resultados.values())[0][0].shape[3]\n",
        "input_shape = (num_escalas, coeficientes , canales)\n",
        "\n",
        "num_classes = 3\n",
        "batch_size = 1\n",
        "epochs = 50\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(64, input_shape=(input_shape[1], input_shape[0]*input_shape[2]), return_sequences=True,  activation=\"tanh\",\n",
        "    recurrent_activation=\"sigmoid\"))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(32,activation=\"tanh\", recurrent_activation=\"sigmoid\", return_sequences=False))\n",
        "model.add(Dropout(0.2))\n",
        "#model.add(LSTM(100,return_sequences=True))\n",
        "#model.add(Dropout(0.2))\n",
        "#model.add(LSTM(50))\n",
        "#model.add(Dropout(0.2))\n",
        "model.add(Dense(3, activation='softmax'))\n",
        "\n",
        "    \n",
        "METRICS = ['accuracy',\n",
        "      tf.keras.metrics.TruePositives(name='tp'),\n",
        "      tf.keras.metrics.FalsePositives(name='fp'),\n",
        "      tf.keras.metrics.TrueNegatives(name='tn'),\n",
        "      tf.keras.metrics.FalseNegatives(name='fn'),\n",
        "      tfa.metrics.F1Score(name= 'f1_score', num_classes=3, average = 'macro'),\n",
        "      #tfa.metrics.F1Score(num_classes = 6, average = \"macro\",name = \"f1_score\")\n",
        "      tf.keras.metrics.CategoricalCrossentropy(name='categorical_crossentropy'),\n",
        "      tf.keras.metrics.Precision(name='precision'),\n",
        "      tf.keras.metrics.Recall(name='recall'),\n",
        "      tf.keras.metrics.AUC(name='auc'),\n",
        "      tf.keras.metrics.AUC(name='prc', curve='PR'), # precision-recall curve\n",
        "]\n",
        "\n",
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
        "                metrics=['accuracy',\n",
        "                tfa.metrics.F1Score(name= 'f1_score', num_classes=3),\n",
        "                tf.keras.metrics.CategoricalCrossentropy(name='categorical_crossentropy'),\n",
        "                tf.keras.metrics.Precision(name='precision'),\n",
        "                tf.keras.metrics.Recall(name='recall')])\n",
        "\n",
        "\n",
        "#model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "#              optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
        "#                metrics= METRICS)\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "ZBXAFxn1eH-2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "737ddfd9-e1fc-4c59-efbb-092e50e211c8"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-17014bca4de8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mnum_escalas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresultados\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mcoeficientes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresultados\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mcanales\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresultados\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_callbacks(model, metric = 'val_accuracy'):\n",
        "    \n",
        "    #guardar_path = '/home/inaki/temp/mejor_modelo_'+ model.name + '.h5'\n",
        "    \n",
        "    #checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
        "    #    filepath = guardar_path,\n",
        "    #    monitor = metric,\n",
        "    #    mode ='max',\n",
        "    #    save_best_only=True,\n",
        "    #    verbose=1,\n",
        "    #)\n",
        "    \n",
        "    reduccionlr = tf.keras.callbacks.ReduceLROnPlateau(\n",
        "        monitor = metric,\n",
        "        mode = 'max',\n",
        "        factor = 0.1,\n",
        "        patience = 3,\n",
        "        verbose = 0\n",
        "    )\n",
        "\n",
        "    earlystop = tf.keras.callbacks.EarlyStopping(\n",
        "        monitor = metric,\n",
        "        mode ='max',\n",
        "        patience = 5, \n",
        "        verbose = 1\n",
        "    )\n",
        "    \n",
        "    callbacks = [reduccionlr, earlystop]         \n",
        "    \n",
        "    return callbacks"
      ],
      "metadata": {
        "id": "_19ExnK8fANs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_callbacks = [\n",
        "    tf.keras.callbacks.EarlyStopping(monitor = 'val_f1_score', patience=5, mode='max', verbose = 1),\n",
        "    tf.keras.callbacks.ReduceLROnPlateau(monitor = 'val_f1_score',  factor = 0.1, patience = 3, verbose =0),\n",
        "]"
      ],
      "metadata": {
        "id": "W10BWxPBfCya"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_model(data, labels):\n",
        "    from random import sample\n",
        "    \n",
        "    train_data_cwt = data\n",
        "    train_data_cwt_labels = labels\n",
        "    \n",
        "    #print(train_data_cwt.shape)\n",
        "    #print(train_data_cwt_labels.shape)\n",
        "    \n",
        "    items = [item for sublist in train_data_cwt_labels[:,:,-1] for item in sublist]\n",
        "\n",
        "    import collections\n",
        "\n",
        "    # using Counter from Dict() to find frequency of elements\n",
        "    balanceo = collections.Counter(items)\n",
        "    suma = sum(balanceo.values())\n",
        "    for k, v in balanceo.items():\n",
        "        balanceo[k] = (1/v)*(suma/3)\n",
        "    print(\"Balanceo clases : {}\".format(dict(balanceo)))\n",
        "\n",
        "    from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    #num_instances, escalas, coef, num_canales = train_data_cwt.shape\n",
        "    train_data = np.reshape(train_data_cwt, (-1, train_data_cwt.shape[-1]))\n",
        "    train_data = scaler.fit_transform(train_data)\n",
        "    train_data = np.reshape(train_data, (train_data_cwt.shape[0], train_data_cwt.shape[1], train_data_cwt.shape[2], train_data_cwt.shape[-1]))\n",
        "    \n",
        "    random_num_generated = int(sample(range(0,99), 1)[0])\n",
        "    \n",
        "    # Ensure that we get at least one sample of each class on both train and test\n",
        "    X_train, X_test, y_train, y_test = train_test_split(train_data, train_data_cwt_labels,  test_size=0.3, random_state = random_num_generated)\n",
        "    #print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
        "    \n",
        "    y_train_cat = tf.keras.utils.to_categorical(y_train[:,-1,-1], 3)\n",
        "    y_test_cat = tf.keras.utils.to_categorical(y_test[:,-1,-1], 3)\n",
        "    \n",
        "    #print(\"Shapes\", y_train_cat.shape, y_test_cat.shape)\n",
        "    \n",
        "    # Ensure that we get at least one sample of each class on both train and test\n",
        "    while len(set(np.argmax(y_test_cat, axis=1).tolist())) < len(set(np.argmax(y_train_cat, axis=1).tolist())):\n",
        "        random_num_generated = int(sample(range(0,99), 1)[0])\n",
        "        X_train, X_test, y_train, y_test = train_test_split(train_data, train_data_cwt_labels,  test_size=0.3, random_state = random_num_generated)\n",
        "        y_train_cat = tf.keras.utils.to_categorical(y_train[:,-1,-1], 3)\n",
        "        y_test_cat = tf.keras.utils.to_categorical(y_test[:,-1,-1], 3)\n",
        "    \n",
        "    print(\"Y shapes before\", y_train_cat.shape, y_test_cat.shape)\n",
        "    print(\"X shapes before\", X_train.shape, X_test.shape)\n",
        "    \n",
        "    X_train = X_train.reshape(X_train.shape[0], 128, -1)\n",
        "    X_test = X_test.reshape(X_test.shape[0], 128, -1)\n",
        "    \n",
        "    y_train_cat = y_train_cat.reshape(y_train_cat.shape[0], -1)\n",
        "    y_test_cat = y_test_cat.reshape(y_test_cat.shape[0], -1)\n",
        "    \n",
        "    print(\"Y shapes AFTER\", y_train_cat.shape, y_test_cat.shape)\n",
        "    print(\"X shapes AFTER\", X_train.shape, X_test.shape)\n",
        "    \n",
        "    batch_size = 1\n",
        "    epochs = 30\n",
        "    \n",
        "    \n",
        "    METRICS = ['accuracy',\n",
        "      tf.keras.metrics.TruePositives(name='tp'),\n",
        "      tf.keras.metrics.FalsePositives(name='fp'),\n",
        "      tf.keras.metrics.TrueNegatives(name='tn'),\n",
        "      tf.keras.metrics.FalseNegatives(name='fn'),\n",
        "      tfa.metrics.F1Score(name= 'f1_score', num_classes=3),\n",
        "      tf.keras.metrics.CategoricalCrossentropy(name='categorical_crossentropy'),\n",
        "      tf.keras.metrics.Precision(name='precision'),\n",
        "      tf.keras.metrics.Recall(name='recall'),\n",
        "      tf.keras.metrics.AUC(name='auc'),\n",
        "      tf.keras.metrics.AUC(name='prc', curve='PR'), # precision-recall curve\n",
        "]\n",
        "    \n",
        "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
        "              metrics= METRICS)\n",
        "    \n",
        "    history = History()\n",
        "    history = model.fit(X_train, y_train_cat,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test_cat),\n",
        "          #callbacks = my_callbacks,\n",
        "          callbacks = [history],\n",
        "          class_weight = balanceo)\n",
        "\n",
        "    ultimos = dict()\n",
        "    \n",
        "    for k, v in history.history.items():\n",
        "        ultimos.update({k: v[-1]})  \n",
        "    #return X_train, X_test, y_train_cat, y_test_cat\n",
        "    return ultimos"
      ],
      "metadata": {
        "id": "FyckYKpgfIsK"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "historias = dict()\n",
        "for k, v in resultados.items():\n",
        "    #a = v[0]\n",
        "    #b = v[1]\n",
        "    #print(a.shape, b.shape)\n",
        "    hist_temp = process_model(v[0], v[1])\n",
        "    historias.update({k:hist_temp})"
      ],
      "metadata": {
        "id": "ZsvzJ2YofLj6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "historias_df = pd.DataFrame(historias)\n",
        "now = datetime.now()\n",
        "dt_string = now.strftime(\"%d_%m_%Y_%H_%M_%S\")\n",
        "historias_df.to_csv('/kaggle/working/historias_df_LSTM'+dt_string+'.csv', sep=',', na_rep='', header=True, index=True, mode='w')"
      ],
      "metadata": {
        "id": "2oXl25wEhTYw"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "1QEDghShWB33nFYRS1rN1gMKKuY4ThXxG",
      "authorship_tag": "ABX9TyPr+kWsF2DzPWRfF+ytuH5I",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}